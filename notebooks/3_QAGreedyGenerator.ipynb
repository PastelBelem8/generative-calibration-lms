{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f349d70",
   "metadata": {},
   "source": [
    "# 3. Scores Generator (A)\n",
    "\n",
    "We have divided this notebook into the following parts:\n",
    "\n",
    "1. Load **matrix**: We load a CSV file with the preprocessed matrix. \n",
    "2. Load **model**: Using hugging face API, we load a pre-trained or a fine-tuned model and apply it to the said matrix to obtain corresponding predictions.\n",
    "\n",
    "3. **Model-specific preprocessing**: We apply model specific fine-tuning that is related with how the models were trained to encode the strings.\n",
    "3. Create **preds**: We create a CSV file with the predictions concerning the model to evaluate.\n",
    "\n",
    "**Note**: We assume that all matrices have a set of `ID_COLS` that uniquely identifies each row. Additionally, for multi-way (or multi-annotated) datasets, we assume a row-wise format, that is, all the necessary data has already been unrolled  along the first dimension. For example, let us consider a __source dataset__ with $200$ examples, where each of them comprises two different annotations. This notebook __assumes that dataset was previously preprocessed__ and is __now unflattened__ totalling $400$ rows (one per example and annotation) when loaded from memory. While this duplicates memory, it avoids having complex pipelines with intrinsic hand-tailored routines for each dataset (i.e., _bye bye spaghetti_ code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3173c1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using example_id as the unique column to de-duplicate the data\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = \"../outputs\"\n",
    "\n",
    "# TODO - Come up with some uuid (model_name + dataset + split)\n",
    "BASE_FILENAME = \"dev4-uqa-t5-small\"\n",
    "ROOT_DIR = f\"{OUTPUT_DIR}/results/mocha/narrativeqa/dev4\"\n",
    "\n",
    "MATRIX_DIR = f\"{ROOT_DIR}/matrix\"\n",
    "MATRIX_FILEPATH = f\"{MATRIX_DIR}/{BASE_FILENAME}.csv.gz\"\n",
    "\n",
    "# Outputs\n",
    "PREDS_DIR = f\"{ROOT_DIR}/preds\"\n",
    "!mkdir -p {PREDS_DIR}\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "# Arguments used to read the files from disk\n",
    "csv_kwargs = {\n",
    "   \"compression\": \"gzip\",\n",
    "   \"encoding\": \"utf-8\",\n",
    "}\n",
    "\n",
    "# ----------------------------------------\n",
    "## Columns names\n",
    "# ----------------------------------------\n",
    "ID_COLS = [\"example_id\", \"answer_id\"]\n",
    "\n",
    "UNIQUE_ID_COL = ID_COLS[0]\n",
    "NON_UNIQUE_ID_COL = ID_COLS[1]\n",
    "print(\"Using\", UNIQUE_ID_COL, \"as the unique column to de-duplicate the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e39fac",
   "metadata": {},
   "source": [
    "## Load matrix \n",
    "\n",
    "This is the preprocessed matrix that will be used by every model when creating predictions. We expect it to  have the following columns:\n",
    "- `ID_COLS: List[str]`, can be one or more set of unique identifier columns.\n",
    "- `TOPIC: str`, optional, provides a high-level categorization of the different examples.\n",
    "\n",
    "- Dataset specific columns, such as `CONTEXT`, `QUESTION`, `ANSWER` for open-book (closed-domain) QA tasks. Amongst these we usually define the `TARGET_LABEL` and the `FEATURES` the ones that will be encoded together for generative purposes.\n",
    "\n",
    "\n",
    "By default we will assume the following columns:\n",
    "- `TARGET_LABEL = 'label'`\n",
    "- `FEATURES = ['question', 'context']`\n",
    "\n",
    "\n",
    "**Note**: ~~May have to reconsider the use of pandas, for larger datasets, since it wont be feasible to hold them in memory. Instead, may consider HuggingFace `datasets` or `pyspark`.~~ Consider [building script](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-or-remote-files) in case more demanding needs arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60de8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd48ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LABEL = \"label\"\n",
    "FEATURES = [\"question\", \"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dff899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-10dc393789c9a3ef\n",
      "Reusing dataset csv (/home/kat/.cache/huggingface/datasets/csv/default-10dc393789c9a3ef/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac1ad282aee4b178f0be01953225396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 445 datapoints from ../outputs/results/mocha/narrativeqa/dev4/matrix/dev4-uqa-t5-small.csv.gz\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "matrix = datasets.load_dataset('csv', data_files=MATRIX_FILEPATH)[\"train\"]\n",
    "print(\"Loaded\", len(matrix), \"datapoints from\", MATRIX_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc985ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['example_id', 'answer_id', 'title', 'context', 'question', 'label', 'multi_way_labels'],\n",
       "    num_rows: 445\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd895cf5",
   "metadata": {},
   "source": [
    "### Remove duplicate entries when generating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7464e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import drop_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a9aca1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/kat/.cache/huggingface/datasets/csv/default-10dc393789c9a3ef/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-4250be564768902f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining 277 datapoints after dropping duplicates\n"
     ]
    }
   ],
   "source": [
    "matrix = drop_duplicates(matrix, UNIQUE_ID_COL)\n",
    "print(\"Remaining\", len(matrix), \"datapoints after dropping duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d440a",
   "metadata": {},
   "source": [
    "## Load model\n",
    "\n",
    "Using HF's API, we load a pre-trained or a fine-tuned model and apply it to the said matrix to obtain corresponding predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7d9ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import T5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b036ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"allenai/unifiedqa-t5-small\"\n",
    "model_name = \"t5-small\"\n",
    "model_hf_kwargs = {\n",
    "    # Path to directory to store the pretrained models\n",
    "    # (may make ensuing analysis faster)\n",
    "    \"cache_dir\": f\"{OUTPUT_DIR}/model/cache\",\n",
    "    # Specific version of the model to use (defaults to main)\n",
    "    # \"revision\": \"main\",\n",
    "}\n",
    "\n",
    "model_hyperparameters = {\n",
    "    \"padding\": \"max_length\",\n",
    "    \"max_length\": 512,\n",
    "    \n",
    "    \"truncation\": True,\n",
    "    \"add_special_tokens\": True,\n",
    "    \"return_attention_mask\": True,\n",
    "    # All generate-specific kwargs should start with the prefix \"generate_\" \n",
    "    \"generate__max_length\": 100,\n",
    "    \"generate__batch_size\": 200,\n",
    "}\n",
    "\n",
    "model = T5Model(model_name, model_hyperparameters, model_hf_kwargs)\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81cc15",
   "metadata": {},
   "source": [
    "## Generate predictions\n",
    "Using the model and the preprocessed matrix, generate the predictions. \n",
    "The predictions files will contain the following information:\n",
    "\n",
    "Useful resources:\n",
    "- [dataset and Pytorch](https://huggingface.co/docs/datasets/use_dataset.html)\n",
    "- [fine-tuning a pretrained model](https://huggingface.co/course/chapter3/4?fw=pt)\n",
    "- [generator](https://huggingface.co/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.generation_utils.GreedySearchDecoderOnlyOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6933a7fc",
   "metadata": {},
   "source": [
    "### Model-tailored Preprocessing\n",
    "\n",
    "We apply model specific fine-tuning that is related with how the models were trained to encode the strings. We will apply this on a per-batch basis to avoid additional overhead in iterating the datasets. We use the [`datasets.Dataset.set_format`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.set_format) as a more efficient way to cast the necessary columns to pytorch structures. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ddf91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a5431a78814ac593be17e090be0dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cad7d3ba3f4841a9f01824e0542d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True} to encode (target=encoded, prefix=None): {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True}\n"
     ]
    }
   ],
   "source": [
    "matrix_fmt = matrix.map(model._format_row, fn_kwargs={\"features\": FEATURES})\n",
    "matrix_fmt = matrix_fmt.map(lambda examples: model.encode(examples, 'encoded'), batched=True)\n",
    "matrix_fmt.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], output_all_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4634dec",
   "metadata": {},
   "source": [
    "### Creating Greedy Predictions\n",
    "\n",
    "We want to be able to create predictions both for __beam search__ and for __greedy search__. We will focus for now in the case when we have a single return sequence (even though we can have multiple beams or multiple paths explored).\n",
    "\n",
    "A predictions matrix will have the following attributes/columns:\n",
    "- `ID_COLUMNS`: ideally comprised of the unique identifiers you specified in the beginning.\n",
    "- `pred_id`: unique identifier for each example (computed for each instance based on the model_uuid and the generated tokens).\n",
    "- `score_proba`: score associated with the generated sentence. computed as the multiplication of the individual raw_scores. the score is within $[0, 1]$.\n",
    "- `preds`: textual representation of the generated instance\n",
    "- `preds_raw_int`: tokens id \n",
    "- `preds_raw_str`: tokens str\n",
    "- `preds_raw_scores`: scores for each of the tokens, lie in the range $[0, 1]$.\n",
    "- `len`: length of the sentence\n",
    "- `truncated`: whether the sequence was truncated (i.e., actually had the eos token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "382b7fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.predictions import GreedyGenerator\n",
    "from utils_generic import filter_params_by_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47292c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator kwargs: {'max_length': 100, 'batch_size': 200}\n",
      "Creating **Greedy Generator**\n",
      "Generating...\n"
     ]
    }
   ],
   "source": [
    "GENERATE_PREFIX = \"generate__\"\n",
    "\n",
    "model_generate_hyperparams = filter_params_by_prefix(model_hyperparameters, GENERATE_PREFIX)\n",
    "model_generate_hyperparams = {param_name[len(GENERATE_PREFIX):]: param_val for param_name, param_val in model_generate_hyperparams.items()}\n",
    "print(\"Generator kwargs:\", model_generate_hyperparams)\n",
    "\n",
    "\n",
    "print(\"Creating **Greedy Generator**\")\n",
    "generator = GreedyGenerator()\n",
    "\n",
    "print(\"Generating...\")\n",
    "batches = generator.generate(\n",
    "    data=matrix_fmt,\n",
    "    id_cols=ID_COLS,\n",
    "    model=model._model,\n",
    "    tokenizer=model._tokenizer,\n",
    "    **model_generate_hyperparams,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26319c06",
   "metadata": {},
   "source": [
    "## Dump prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58bf26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.output import OutputResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d09db3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predictions at: dev4-uqa-t5-small\n",
      "Processing examples 0-200\n",
      "Processing examples 200-277\n"
     ]
    }
   ],
   "source": [
    "# Sanity check (:\n",
    "out_result = OutputResult(\n",
    "    filename=BASE_FILENAME,\n",
    "    output_dir=PREDS_DIR,\n",
    "    out_extension=\".csv.gz\",\n",
    ")\n",
    "\n",
    "print(\"Writing predictions at:\", out_result.filename)\n",
    "out_result.write(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce0eb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_id</th>\n",
       "      <th>preds_raw_int</th>\n",
       "      <th>preds_raw_str</th>\n",
       "      <th>preds_raw_count</th>\n",
       "      <th>truncated</th>\n",
       "      <th>score_proba</th>\n",
       "      <th>preds_raw_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e6b688ad84546d681f1339df539a0b2</td>\n",
       "      <td>618baa6d3449a6d9171cd39bf204e8c9</td>\n",
       "      <td>doctor pascal rougon</td>\n",
       "      <td>abe46eacce04f58879f56150c248564d</td>\n",
       "      <td>[2472, 330, 1489, 3, 3964, 5307, 1]</td>\n",
       "      <td>['▁doctor', '▁pas', 'cal', '▁', 'rou', 'gon']</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.444278</td>\n",
       "      <td>[0.4561927914619446, 0.9993246793746948, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2aea58b6733f531e127a96752d9db1a4</td>\n",
       "      <td>52e62d271a8dbbc887e25f68681794b4</td>\n",
       "      <td>converts</td>\n",
       "      <td>88a6dc645c7d491d08aece45c8eaca71</td>\n",
       "      <td>[5755, 7, 1]</td>\n",
       "      <td>['▁convert', 's']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.685860</td>\n",
       "      <td>[0.8886100649833679, 0.9971410036087036, 0.774...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a9bf0ee9eac598663c3f2c9a9908b1e6</td>\n",
       "      <td>2093f3df3379e16364141294a8c9a062</td>\n",
       "      <td>into a \"swimming tank\"</td>\n",
       "      <td>4e6598f9b608b3f532f4f1e537e461a8</td>\n",
       "      <td>[139, 3, 9, 96, 7, 210, 23, 635, 53, 5040, 121...</td>\n",
       "      <td>['▁into', '▁', 'a', '▁\"', 's', 'w', 'i', 'mm',...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.549538</td>\n",
       "      <td>[0.7651848196983337, 0.9803006052970886, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f485d3509a0606a7b570cc5f2edbd083</td>\n",
       "      <td>e2fd235719de9140057fdb4e61e930e9</td>\n",
       "      <td>a competition of \"court compliment\"</td>\n",
       "      <td>36bbc8a0cef5d357cacd366611cc23cf</td>\n",
       "      <td>[3, 9, 2259, 13, 96, 14492, 12064, 121, 1]</td>\n",
       "      <td>['▁', 'a', '▁competition', '▁of', '▁\"', 'court...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.397013</td>\n",
       "      <td>[0.45407742261886597, 0.9586191773414612, 0.97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>921d4e8c8c14e3b385bb80546b792154</td>\n",
       "      <td>8266b87c9f4982b8d7ed33efba54537b</td>\n",
       "      <td>a gypsy boy, pablo</td>\n",
       "      <td>6a2bcdc69999a8d9394ff25f86d6580e</td>\n",
       "      <td>[3, 9, 3, 122, 63, 19819, 4940, 6, 2576, 4672, 1]</td>\n",
       "      <td>['▁', 'a', '▁', 'g', 'y', 'psy', '▁boy', ',', ...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159552</td>\n",
       "      <td>[0.60820072889328, 0.5329287648200989, 0.94543...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>cb25a066e09c116f9519a5a77e9a0b5f</td>\n",
       "      <td>b0b95faf20f3d7991d8bb09a1e08a4ae</td>\n",
       "      <td>patience</td>\n",
       "      <td>3b5bfb437430411c9990d029972d497b</td>\n",
       "      <td>[11998, 1]</td>\n",
       "      <td>['▁patience']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.784210</td>\n",
       "      <td>[0.8764204978942871, 0.8947873711585999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>92cf35db62a8b8b885ae6bd88b74796e</td>\n",
       "      <td>83eeb53928af196b2521ec80c13d3594</td>\n",
       "      <td>alexandria</td>\n",
       "      <td>ddc42a3937dc82ea8f2a094e82c6b1eb</td>\n",
       "      <td>[1240, 226, 232, 52, 23, 9, 1]</td>\n",
       "      <td>['▁ale', 'x', 'and', 'r', 'i', 'a']</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.911054</td>\n",
       "      <td>[0.9166272878646851, 0.999991774559021, 0.9999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>3215cbad5038466d27701023ed9b1425</td>\n",
       "      <td>b07f2a24dd9d08626ce39fbc31afa97c</td>\n",
       "      <td>lady mabel grex</td>\n",
       "      <td>c95fd0ced49c47fe215d16c97d51d870</td>\n",
       "      <td>[9360, 954, 2370, 3542, 994, 1]</td>\n",
       "      <td>['▁lady', '▁ma', 'bel', '▁gr', 'ex']</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.593904</td>\n",
       "      <td>[0.8748897314071655, 0.6942368745803833, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>69fb15c137edf9c225875ffa7112906a</td>\n",
       "      <td>e23c2e8728e615c361a843ec13823480</td>\n",
       "      <td>frank tregear</td>\n",
       "      <td>4e5be9eac0b8795072ddc8f213d9a44e</td>\n",
       "      <td>[3, 89, 6254, 3, 929, 397, 291, 1]</td>\n",
       "      <td>['▁', 'f', 'rank', '▁', 'tre', 'ge', 'ar']</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137433</td>\n",
       "      <td>[0.2087908536195755, 0.6718899011611938, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>67097f32f76f45666a6f5371a5aae5f1</td>\n",
       "      <td>11f5bdf3930169e5a69235baadcd872d</td>\n",
       "      <td>philammon</td>\n",
       "      <td>8e2025ffac54e31e7ca4f8cd143d8272</td>\n",
       "      <td>[3, 18118, 265, 2157, 1]</td>\n",
       "      <td>['▁', 'phil', 'am', 'mon']</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885049</td>\n",
       "      <td>[0.9063522219657898, 0.9851705431938171, 0.999...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           example_id                         answer_id  \\\n",
       "0    2e6b688ad84546d681f1339df539a0b2  618baa6d3449a6d9171cd39bf204e8c9   \n",
       "1    2aea58b6733f531e127a96752d9db1a4  52e62d271a8dbbc887e25f68681794b4   \n",
       "2    a9bf0ee9eac598663c3f2c9a9908b1e6  2093f3df3379e16364141294a8c9a062   \n",
       "3    f485d3509a0606a7b570cc5f2edbd083  e2fd235719de9140057fdb4e61e930e9   \n",
       "4    921d4e8c8c14e3b385bb80546b792154  8266b87c9f4982b8d7ed33efba54537b   \n",
       "..                                ...                               ...   \n",
       "272  cb25a066e09c116f9519a5a77e9a0b5f  b0b95faf20f3d7991d8bb09a1e08a4ae   \n",
       "273  92cf35db62a8b8b885ae6bd88b74796e  83eeb53928af196b2521ec80c13d3594   \n",
       "274  3215cbad5038466d27701023ed9b1425  b07f2a24dd9d08626ce39fbc31afa97c   \n",
       "275  69fb15c137edf9c225875ffa7112906a  e23c2e8728e615c361a843ec13823480   \n",
       "276  67097f32f76f45666a6f5371a5aae5f1  11f5bdf3930169e5a69235baadcd872d   \n",
       "\n",
       "                                   preds                          preds_id  \\\n",
       "0                   doctor pascal rougon  abe46eacce04f58879f56150c248564d   \n",
       "1                               converts  88a6dc645c7d491d08aece45c8eaca71   \n",
       "2                 into a \"swimming tank\"  4e6598f9b608b3f532f4f1e537e461a8   \n",
       "3    a competition of \"court compliment\"  36bbc8a0cef5d357cacd366611cc23cf   \n",
       "4                     a gypsy boy, pablo  6a2bcdc69999a8d9394ff25f86d6580e   \n",
       "..                                   ...                               ...   \n",
       "272                             patience  3b5bfb437430411c9990d029972d497b   \n",
       "273                           alexandria  ddc42a3937dc82ea8f2a094e82c6b1eb   \n",
       "274                      lady mabel grex  c95fd0ced49c47fe215d16c97d51d870   \n",
       "275                        frank tregear  4e5be9eac0b8795072ddc8f213d9a44e   \n",
       "276                            philammon  8e2025ffac54e31e7ca4f8cd143d8272   \n",
       "\n",
       "                                         preds_raw_int  \\\n",
       "0                  [2472, 330, 1489, 3, 3964, 5307, 1]   \n",
       "1                                         [5755, 7, 1]   \n",
       "2    [139, 3, 9, 96, 7, 210, 23, 635, 53, 5040, 121...   \n",
       "3           [3, 9, 2259, 13, 96, 14492, 12064, 121, 1]   \n",
       "4    [3, 9, 3, 122, 63, 19819, 4940, 6, 2576, 4672, 1]   \n",
       "..                                                 ...   \n",
       "272                                         [11998, 1]   \n",
       "273                     [1240, 226, 232, 52, 23, 9, 1]   \n",
       "274                    [9360, 954, 2370, 3542, 994, 1]   \n",
       "275                 [3, 89, 6254, 3, 929, 397, 291, 1]   \n",
       "276                           [3, 18118, 265, 2157, 1]   \n",
       "\n",
       "                                         preds_raw_str  preds_raw_count  \\\n",
       "0        ['▁doctor', '▁pas', 'cal', '▁', 'rou', 'gon']                6   \n",
       "1                                    ['▁convert', 's']                2   \n",
       "2    ['▁into', '▁', 'a', '▁\"', 's', 'w', 'i', 'mm',...               11   \n",
       "3    ['▁', 'a', '▁competition', '▁of', '▁\"', 'court...                8   \n",
       "4    ['▁', 'a', '▁', 'g', 'y', 'psy', '▁boy', ',', ...               10   \n",
       "..                                                 ...              ...   \n",
       "272                                      ['▁patience']                1   \n",
       "273                ['▁ale', 'x', 'and', 'r', 'i', 'a']                6   \n",
       "274               ['▁lady', '▁ma', 'bel', '▁gr', 'ex']                5   \n",
       "275         ['▁', 'f', 'rank', '▁', 'tre', 'ge', 'ar']                7   \n",
       "276                         ['▁', 'phil', 'am', 'mon']                4   \n",
       "\n",
       "     truncated  score_proba                                   preds_raw_scores  \n",
       "0            1     0.444278  [0.4561927914619446, 0.9993246793746948, 0.999...  \n",
       "1            1     0.685860  [0.8886100649833679, 0.9971410036087036, 0.774...  \n",
       "2            1     0.549538  [0.7651848196983337, 0.9803006052970886, 0.999...  \n",
       "3            1     0.397013  [0.45407742261886597, 0.9586191773414612, 0.97...  \n",
       "4            1     0.159552  [0.60820072889328, 0.5329287648200989, 0.94543...  \n",
       "..         ...          ...                                                ...  \n",
       "272          1     0.784210           [0.8764204978942871, 0.8947873711585999]  \n",
       "273          1     0.911054  [0.9166272878646851, 0.999991774559021, 0.9999...  \n",
       "274          1     0.593904  [0.8748897314071655, 0.6942368745803833, 0.999...  \n",
       "275          1     0.137433  [0.2087908536195755, 0.6718899011611938, 0.999...  \n",
       "276          1     0.885049  [0.9063522219657898, 0.9851705431938171, 0.999...  \n",
       "\n",
       "[277 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(out_result.filepath, compression=\"gzip\", encoding=\"utf-8\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b423017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
