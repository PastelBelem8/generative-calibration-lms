{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f349d70",
   "metadata": {},
   "source": [
    "# 3. Scores Generator (A)\n",
    "\n",
    "We have divided this notebook into the following parts:\n",
    "\n",
    "1. Load **matrix**: We load a CSV file with the preprocessed matrix. \n",
    "2. Load **model**: Using hugging face API, we load a pre-trained or a fine-tuned model and apply it to the said matrix to obtain corresponding predictions.\n",
    "\n",
    "3. **Model-specific preprocessing**: We apply model specific fine-tuning that is related with how the models were trained to encode the strings.\n",
    "3. Create **preds**: We create a CSV file with the predictions concerning the model to evaluate.\n",
    "\n",
    "**Note**: We assume that all matrices have a set of `ID_COLS` that uniquely identifies each row. Additionally, for multi-way (or multi-annotated) datasets, we assume a row-wise format, that is, all the necessary data has already been unrolled  along the first dimension. For example, let us consider a __source dataset__ with $200$ examples, where each of them comprises two different annotations. This notebook __assumes that dataset was previously preprocessed__ and is __now unflattened__ totalling $400$ rows (one per example and annotation) when loaded from memory. While this duplicates memory, it avoids having complex pipelines with intrinsic hand-tailored routines for each dataset (i.e., _bye bye spaghetti_ code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3173c1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using example_id as the unique column to de-duplicate the data\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = \"../outputs\"\n",
    "\n",
    "MODEL_NAME = \"allenai/unifiedqa-t5-small\"\n",
    "#model_name = \"t5-small\"\n",
    "\n",
    "# name of the dataset to preprocess\n",
    "# DATASET_NAME, SPLIT_NAME = \"squad\", \"validation\"\n",
    "# DATASET_NAME, SPLIT_NAME = \"newsqa\", \"dev\"\n",
    "# DATASET_NAME, SPLIT_NAME = ('squadshifts', 'new_wiki'), \"test\"\n",
    "# DATASET_NAME, SPLIT_NAME = ('squadshifts', 'nyt'), \"test\"\n",
    "# DATASET_NAME, SPLIT_NAME = ('squadshifts', 'amazon'), \"test\"\n",
    "# DATASET_NAME, SPLIT_NAME = ('squadshifts', 'reddit'), \"test\"\n",
    "# DATASET_NAME, SPLIT_NAME = \"narrativeqa\", \"test_5k_sample_seed_2022\"\n",
    "DATASET_NAME, SPLIT_NAME = \"narrativeqa\", \"test_len_10\"\n",
    "\n",
    "\n",
    "IS_LOCAL_FS_DATASET = True \\\n",
    "    if (DATASET_NAME in (\"newsqa\", ) or SPLIT_NAME in (\"test_5k_sample_seed_2022\",)) \\\n",
    "    else False\n",
    "\n",
    "if isinstance(DATASET_NAME, tuple):\n",
    "    NORMALIZED_DATASET_NAME = \"\".join(DATASET_NAME)\n",
    "else:\n",
    "    NORMALIZED_DATASET_NAME = DATASET_NAME\n",
    "\n",
    "BASE_FILENAME = f\"{NORMALIZED_DATASET_NAME}_{SPLIT_NAME}\"\n",
    "\n",
    "\n",
    "ROOT_DIR = f\"{OUTPUT_DIR}/results/{NORMALIZED_DATASET_NAME}/{SPLIT_NAME}\"\n",
    "\n",
    "MATRIX_DIR = f\"{ROOT_DIR}/matrix\"\n",
    "MATRIX_FILEPATH = f\"{MATRIX_DIR}/{BASE_FILENAME}_preprocessed.csv\"\n",
    "\n",
    "# Outputs\n",
    "PREDS_DIR = f\"{ROOT_DIR}/preds\"\n",
    "!mkdir -p {PREDS_DIR}\n",
    "\n",
    "SEED = 42\n",
    "# Arguments used to read the files from disk\n",
    "csv_kwargs = {\n",
    "   \"compression\": \"gzip\",\n",
    "   \"encoding\": \"utf-8\",\n",
    "}\n",
    "\n",
    "# ----------------------------------------\n",
    "## Columns names\n",
    "# ----------------------------------------\n",
    "ID_COLS = [\"example_id\", \"answer_id\"]\n",
    "\n",
    "UNIQUE_ID_COL = ID_COLS[0]\n",
    "NON_UNIQUE_ID_COL = ID_COLS[1]\n",
    "print(\"Using\", UNIQUE_ID_COL, \"as the unique column to de-duplicate the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e39fac",
   "metadata": {},
   "source": [
    "## Load matrix \n",
    "\n",
    "This is the preprocessed matrix that will be used by every model when creating predictions. We expect it to  have the following columns:\n",
    "- `ID_COLS: List[str]`, can be one or more set of unique identifier columns.\n",
    "- `TOPIC: str`, optional, provides a high-level categorization of the different examples.\n",
    "\n",
    "- Dataset specific columns, such as `CONTEXT`, `QUESTION`, `ANSWER` for open-book (closed-domain) QA tasks. Amongst these we usually define the `TARGET_LABEL` and the `FEATURES` the ones that will be encoded together for generative purposes.\n",
    "\n",
    "\n",
    "By default we will assume the following columns:\n",
    "- `TARGET_LABEL = 'label'`\n",
    "- `FEATURES = ['question', 'context']`\n",
    "\n",
    "\n",
    "**Note**: ~~May have to reconsider the use of pandas, for larger datasets, since it wont be feasible to hold them in memory. Instead, may consider HuggingFace `datasets` or `pyspark`.~~ Consider [building script](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-or-remote-files) in case more demanding needs arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60de8d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kat/miniconda3/envs/gqa-env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd48ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LABEL = \"label\"\n",
    "FEATURES = [\"question\", \"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dff899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c08f75ec88dbd2c1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/kat/.cache/huggingface/datasets/csv/default-c08f75ec88dbd2c1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2116.20it/s]\n",
      "Extracting data files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1616.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/kat/.cache/huggingface/datasets/csv/default-c08f75ec88dbd2c1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 898.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3205 datapoints from ../outputs/results/narrativeqa/test_len_10/matrix/narrativeqa_test_len_10_preprocessed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "matrix = datasets.load_dataset('csv', data_files=MATRIX_FILEPATH)[\"train\"]\n",
    "print(\"Loaded\", len(matrix), \"datapoints from\", MATRIX_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd895cf5",
   "metadata": {},
   "source": [
    "### Remove duplicate entries when generating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7464e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import drop_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a9aca1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 144.59ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining 3205 datapoints after dropping duplicates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "matrix = drop_duplicates(matrix, UNIQUE_ID_COL)\n",
    "print(\"Remaining\", len(matrix), \"datapoints after dropping duplicates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7621506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['example_id', 'title', 'question', 'context', 'labels', 'multi_way_labels', 'answer_id', 'question_len', 'context_len', 'labels_len'],\n",
       "    num_rows: 3205\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d440a",
   "metadata": {},
   "source": [
    "## Load model\n",
    "\n",
    "Using HF's API, we load a pre-trained or a fine-tuned model and apply it to the said matrix to obtain corresponding predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d9ecf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.nn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_364290/2250014622.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mT5Model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnifiedQAT5Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"unified\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using UnifiedQA:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mMODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnifiedQAT5Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PhD/generative-calibration-lms/notebooks/models/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataclasses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGreedyGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils_generic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfilter_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_params_by_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/PhD/generative-calibration-lms/notebooks/models/predictions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch.nn'"
     ]
    }
   ],
   "source": [
    "from models.model import T5Model, UnifiedQAT5Model\n",
    "\n",
    "if \"unified\" in MODEL_NAME:\n",
    "    print(\"Using UnifiedQA:\", MODEL_NAME)\n",
    "    MODEL = UnifiedQAT5Model\n",
    "elif \"t5\" in MODEL_NAME:\n",
    "    print(\"Using T5 model:\", MODEL_NAME)\n",
    "    MODEL = T5Model\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b036ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hf_kwargs = {\n",
    "    # Path to directory to store the pretrained models\n",
    "    # (may make ensuing analysis faster)\n",
    "    \"cache_dir\": f\"{OUTPUT_DIR}/model/cache\",\n",
    "    # Specific version of the model to use (defaults to main)\n",
    "    # \"revision\": \"main\",\n",
    "}\n",
    "\n",
    "model_hyperparameters = {\n",
    "    \"padding\": \"max_length\",\n",
    "    \"max_length\": 512,\n",
    "    \n",
    "    \"truncation\": True,\n",
    "    \"add_special_tokens\": True,\n",
    "    \"return_attention_mask\": True,\n",
    "    # All generate-specific kwargs should start with the prefix \"generate_\" \n",
    "    \"generate__max_length\": 100,\n",
    "    \"generate__batch_size\": 700,\n",
    "}\n",
    "\n",
    "model = MODEL(MODEL_NAME, model_hyperparameters, model_hf_kwargs)\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81cc15",
   "metadata": {},
   "source": [
    "## Generate predictions\n",
    "Using the model and the preprocessed matrix, generate the predictions. \n",
    "The predictions files will contain the following information:\n",
    "\n",
    "Useful resources:\n",
    "- [dataset and Pytorch](https://huggingface.co/docs/datasets/use_dataset.html)\n",
    "- [fine-tuning a pretrained model](https://huggingface.co/course/chapter3/4?fw=pt)\n",
    "- [generator](https://huggingface.co/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.generation_utils.GreedySearchDecoderOnlyOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6933a7fc",
   "metadata": {},
   "source": [
    "### Model-tailored Preprocessing\n",
    "\n",
    "We apply model specific fine-tuning that is related with how the models were trained to encode the strings. We will apply this on a per-batch basis to avoid additional overhead in iterating the datasets. We use the [`datasets.Dataset.set_format`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.set_format) as a more efficient way to cast the necessary columns to pytorch structures. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95ddf91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc3981608b040d0bdc5126300e13813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe1fb631e7d4615a6641111292dd7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True} to encode (target=encoded, prefix=None): {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True}\n",
      "WARNING:root:Using {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True} to encode (target=encoded, prefix=None): {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True}\n",
      "WARNING:root:Using {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True} to encode (target=encoded, prefix=None): {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True}\n",
      "WARNING:root:Using {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True} to encode (target=encoded, prefix=None): {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True}\n",
      "WARNING:root:Using {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True} to encode (target=encoded, prefix=None): {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True}\n",
      "WARNING:root:Using {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True} to encode (target=encoded, prefix=None): {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True}\n",
      "WARNING:root:Using {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True} to encode (target=encoded, prefix=None): {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True}\n",
      "WARNING:root:Using {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True} to encode (target=encoded, prefix=None): {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True}\n",
      "WARNING:root:Using {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True} to encode (target=encoded, prefix=None): {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True}\n",
      "WARNING:root:Using {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True} to encode (target=encoded, prefix=None): {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True}\n"
     ]
    }
   ],
   "source": [
    "matrix_fmt = matrix.map(model._format_row, fn_kwargs={\"features\": FEATURES})\n",
    "matrix_fmt = matrix_fmt.map(lambda examples: model.encode(examples, 'encoded'), batched=True)\n",
    "matrix_fmt.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], output_all_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4634dec",
   "metadata": {},
   "source": [
    "### Creating Greedy Predictions\n",
    "\n",
    "We want to be able to create predictions both for __beam search__ and for __greedy search__. We will focus for now in the case when we have a single return sequence (even though we can have multiple beams or multiple paths explored).\n",
    "\n",
    "A predictions matrix will have the following attributes/columns:\n",
    "- `ID_COLUMNS`: ideally comprised of the unique identifiers you specified in the beginning.\n",
    "- `pred_id`: unique identifier for each example (computed for each instance based on the model_uuid and the generated tokens).\n",
    "- `score_proba`: score associated with the generated sentence. computed as the multiplication of the individual raw_scores. the score is within $[0, 1]$.\n",
    "- `preds`: textual representation of the generated instance\n",
    "- `preds_raw_int`: tokens id \n",
    "- `preds_raw_str`: tokens str\n",
    "- `preds_raw_scores`: scores for each of the tokens, lie in the range $[0, 1]$.\n",
    "- `len`: length of the sentence\n",
    "- `truncated`: whether the sequence was truncated (i.e., actually had the eos token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "382b7fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.predictions import GreedyGenerator\n",
    "from utils_generic import filter_params_by_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47292c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator kwargs: {'max_length': 100, 'batch_size': 700}\n",
      "Creating **Greedy Generator**\n",
      "Generating...\n"
     ]
    }
   ],
   "source": [
    "GENERATE_PREFIX = \"generate__\"\n",
    "\n",
    "model_generate_hyperparams = filter_params_by_prefix(model_hyperparameters, GENERATE_PREFIX)\n",
    "model_generate_hyperparams = {param_name[len(GENERATE_PREFIX):]: param_val for param_name, param_val in model_generate_hyperparams.items()}\n",
    "print(\"Generator kwargs:\", model_generate_hyperparams)\n",
    "\n",
    "\n",
    "print(\"Creating **Greedy Generator**\")\n",
    "generator = GreedyGenerator()\n",
    "\n",
    "print(\"Generating...\")\n",
    "batches = generator.generate(\n",
    "    data=matrix_fmt,\n",
    "    id_cols=ID_COLS,\n",
    "    model=model._model,\n",
    "    tokenizer=model._tokenizer,\n",
    "    **model_generate_hyperparams,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26319c06",
   "metadata": {},
   "source": [
    "## Dump prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58bf26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.output import OutputResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d09db3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predictions at: squadshiftsreddit_test_squadshiftsreddit_test\n",
      "Processing examples 0-700 (out of 9803)\n",
      "Processing examples 700-1400 (out of 9803)\n",
      "Processing examples 1400-2100 (out of 9803)\n",
      "Processing examples 2100-2800 (out of 9803)\n",
      "Processing examples 2800-3500 (out of 9803)\n",
      "Processing examples 3500-4200 (out of 9803)\n",
      "Processing examples 4200-4900 (out of 9803)\n",
      "Processing examples 4900-5600 (out of 9803)\n",
      "Processing examples 5600-6300 (out of 9803)\n",
      "Processing examples 6300-7000 (out of 9803)\n",
      "Processing examples 7000-7700 (out of 9803)\n",
      "Processing examples 7700-8400 (out of 9803)\n",
      "Processing examples 8400-9100 (out of 9803)\n",
      "Processing examples 9100-9800 (out of 9803)\n",
      "Processing examples 9800-9803 (out of 9803)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check (:\n",
    "out_result = OutputResult(\n",
    "    filename=BASE_FILENAME + f\"_{NORMALIZED_DATASET_NAME}_{SPLIT_NAME}\",\n",
    "    output_dir=PREDS_DIR,\n",
    "    out_extension=\"csv.gz\",\n",
    ")\n",
    "\n",
    "print(\"Writing predictions at:\", out_result.filename)\n",
    "out_result.write(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ce0eb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "example_id          False\n",
       "answer_id           False\n",
       "preds                True\n",
       "preds_id            False\n",
       "preds_raw_int       False\n",
       "preds_raw_str       False\n",
       "preds_raw_count     False\n",
       "truncated           False\n",
       "score_proba         False\n",
       "preds_raw_scores    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(out_result.filepath, compression=\"gzip\", encoding=\"utf-8\")\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f322b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_id</th>\n",
       "      <th>preds_raw_int</th>\n",
       "      <th>preds_raw_str</th>\n",
       "      <th>preds_raw_count</th>\n",
       "      <th>truncated</th>\n",
       "      <th>score_proba</th>\n",
       "      <th>preds_raw_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5d9b75b18ae5305bc982a86b</td>\n",
       "      <td>3b77386b86e94b981a76f05a5f43da45</td>\n",
       "      <td>turn signals and exhaust</td>\n",
       "      <td>27551083ee6365ec2b6561cbafa8aa33</td>\n",
       "      <td>[919, 9650, 11, 10685, 1]</td>\n",
       "      <td>['▁turn', '▁signals', '▁and', '▁exhaust']</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387073</td>\n",
       "      <td>[0.9219509959220886, 0.9995096921920776, 0.526...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5d9b75b18ae5305bc982a869</td>\n",
       "      <td>ff4c857dccfa1633340e74559b52bcb1</td>\n",
       "      <td>a 2010 510 SMR</td>\n",
       "      <td>e1bee9c3f921c59a3b290e94be3ea880</td>\n",
       "      <td>[3, 9, 2735, 3, 25926, 180, 9320, 1]</td>\n",
       "      <td>['▁', 'a', '▁2010', '▁', '510', '▁S', 'MR']</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.421790</td>\n",
       "      <td>[0.8206230401992798, 0.9121021628379822, 0.994...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5d9b75b18ae5305bc982a86a</td>\n",
       "      <td>69670401970f3c9ba88b04d9f7dd1ebf</td>\n",
       "      <td>turn signals, and mirrors</td>\n",
       "      <td>986a63653ca5d44930340e91eac69cb5</td>\n",
       "      <td>[919, 9650, 6, 11, 5432, 7, 1]</td>\n",
       "      <td>['▁turn', '▁signals', ',', '▁and', '▁mirror', ...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355219</td>\n",
       "      <td>[0.8474096655845642, 0.9997405409812927, 0.637...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d9b75b18ae5305bc982a86c</td>\n",
       "      <td>7449ba52d1b5ecda71d9adb1749d4819</td>\n",
       "      <td>the poster and her boyfriend like the SXV mirr...</td>\n",
       "      <td>75419bc260e7ffc02db952288ebb7a4d</td>\n",
       "      <td>[8, 10836, 11, 160, 18124, 114, 8, 180, 4, 553...</td>\n",
       "      <td>['▁the', '▁poster', '▁and', '▁her', '▁boyfrien...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047296</td>\n",
       "      <td>[0.6735487580299377, 0.5055192708969116, 0.946...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5d9bb1b18ae5305bc982d357</td>\n",
       "      <td>3a855fd1b5e0f5ee64350ba22adbfd56</td>\n",
       "      <td>my boyfriend's husky</td>\n",
       "      <td>f32251d4fed562bfc752df4a43baf5c7</td>\n",
       "      <td>[82, 18124, 31, 7, 3, 11823, 3781, 1]</td>\n",
       "      <td>['▁my', '▁boyfriend', \"'\", 's', '▁', 'hus', 'ky']</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378949</td>\n",
       "      <td>[0.8585028052330017, 0.9997809529304504, 0.723...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 example_id                         answer_id  \\\n",
       "0  5d9b75b18ae5305bc982a86b  3b77386b86e94b981a76f05a5f43da45   \n",
       "1  5d9b75b18ae5305bc982a869  ff4c857dccfa1633340e74559b52bcb1   \n",
       "2  5d9b75b18ae5305bc982a86a  69670401970f3c9ba88b04d9f7dd1ebf   \n",
       "3  5d9b75b18ae5305bc982a86c  7449ba52d1b5ecda71d9adb1749d4819   \n",
       "4  5d9bb1b18ae5305bc982d357  3a855fd1b5e0f5ee64350ba22adbfd56   \n",
       "\n",
       "                                               preds  \\\n",
       "0                           turn signals and exhaust   \n",
       "1                                     a 2010 510 SMR   \n",
       "2                          turn signals, and mirrors   \n",
       "3  the poster and her boyfriend like the SXV mirr...   \n",
       "4                               my boyfriend's husky   \n",
       "\n",
       "                           preds_id  \\\n",
       "0  27551083ee6365ec2b6561cbafa8aa33   \n",
       "1  e1bee9c3f921c59a3b290e94be3ea880   \n",
       "2  986a63653ca5d44930340e91eac69cb5   \n",
       "3  75419bc260e7ffc02db952288ebb7a4d   \n",
       "4  f32251d4fed562bfc752df4a43baf5c7   \n",
       "\n",
       "                                       preds_raw_int  \\\n",
       "0                          [919, 9650, 11, 10685, 1]   \n",
       "1               [3, 9, 2735, 3, 25926, 180, 9320, 1]   \n",
       "2                     [919, 9650, 6, 11, 5432, 7, 1]   \n",
       "3  [8, 10836, 11, 160, 18124, 114, 8, 180, 4, 553...   \n",
       "4              [82, 18124, 31, 7, 3, 11823, 3781, 1]   \n",
       "\n",
       "                                       preds_raw_str  preds_raw_count  \\\n",
       "0          ['▁turn', '▁signals', '▁and', '▁exhaust']                4   \n",
       "1        ['▁', 'a', '▁2010', '▁', '510', '▁S', 'MR']                7   \n",
       "2  ['▁turn', '▁signals', ',', '▁and', '▁mirror', ...                6   \n",
       "3  ['▁the', '▁poster', '▁and', '▁her', '▁boyfrien...               13   \n",
       "4  ['▁my', '▁boyfriend', \"'\", 's', '▁', 'hus', 'ky']                7   \n",
       "\n",
       "   truncated  score_proba                                   preds_raw_scores  \n",
       "0          1     0.387073  [0.9219509959220886, 0.9995096921920776, 0.526...  \n",
       "1          1     0.421790  [0.8206230401992798, 0.9121021628379822, 0.994...  \n",
       "2          1     0.355219  [0.8474096655845642, 0.9997405409812927, 0.637...  \n",
       "3          1     0.047296  [0.6735487580299377, 0.5055192708969116, 0.946...  \n",
       "4          1     0.378949  [0.8585028052330017, 0.9997809529304504, 0.723...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "182fef40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_id</th>\n",
       "      <th>preds_raw_int</th>\n",
       "      <th>preds_raw_str</th>\n",
       "      <th>preds_raw_count</th>\n",
       "      <th>truncated</th>\n",
       "      <th>score_proba</th>\n",
       "      <th>preds_raw_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9798</th>\n",
       "      <td>5d9cb4f22358f20614262617</td>\n",
       "      <td>513e64e8c9fda01d49792dc7a25f1810</td>\n",
       "      <td>dota</td>\n",
       "      <td>9373295a57fc51bab0afc62ee2c763e3</td>\n",
       "      <td>[103, 17, 9, 1]</td>\n",
       "      <td>['▁do', 't', 'a']</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495587</td>\n",
       "      <td>[0.5015457272529602, 0.9999641180038452, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9799</th>\n",
       "      <td>5d9cb4f22358f20614262618</td>\n",
       "      <td>fd9de0cc46acc434d7ac9db53f7dff25</td>\n",
       "      <td>some of the most memorable SpongeBob SquarePan...</td>\n",
       "      <td>e6c7ab712ea812ce5b5b69b60611e3bf</td>\n",
       "      <td>[128, 13, 8, 167, 10080, 2526, 2444, 15, 279, ...</td>\n",
       "      <td>['▁some', '▁of', '▁the', '▁most', '▁memorable'...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541317</td>\n",
       "      <td>[0.671987771987915, 0.9991242289543152, 0.9999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9800</th>\n",
       "      <td>5d9cb4f22358f20614262619</td>\n",
       "      <td>82fd14bdbacb142f370d4c9f46bd00dc</td>\n",
       "      <td>commenting on towers, Roshan and hero picks</td>\n",
       "      <td>e3e1f28da0456db79291e84d77a5ae0a</td>\n",
       "      <td>[1670, 53, 30, 7293, 7, 6, 7963, 2618, 11, 160...</td>\n",
       "      <td>['▁comment', 'ing', '▁on', '▁tower', 's', ',',...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.254643</td>\n",
       "      <td>[0.42295578122138977, 0.9977735877037048, 0.98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9801</th>\n",
       "      <td>5d9cb4f22358f2061426261a</td>\n",
       "      <td>ff7435b4b80a6d4ea5f9c384248a4997</td>\n",
       "      <td>make a comment on his love of money</td>\n",
       "      <td>adbeb42e531f3760095e017d026c0df8</td>\n",
       "      <td>[143, 3, 9, 1670, 30, 112, 333, 13, 540, 1]</td>\n",
       "      <td>['▁make', '▁', 'a', '▁comment', '▁on', '▁his',...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.557354</td>\n",
       "      <td>[0.7199561595916748, 0.9998311996459961, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9802</th>\n",
       "      <td>5d9cb4f22358f2061426261b</td>\n",
       "      <td>01afc3ca99156fdf7da380154483e7dc</td>\n",
       "      <td>adding some of the most memorable SpongeBob Sq...</td>\n",
       "      <td>1f53d0d56c593ba266643310dc867821</td>\n",
       "      <td>[2651, 128, 13, 8, 167, 10080, 2526, 2444, 15,...</td>\n",
       "      <td>['▁adding', '▁some', '▁of', '▁the', '▁most', '...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.692029</td>\n",
       "      <td>[0.9828467965126038, 0.9836350679397583, 0.999...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    example_id                         answer_id  \\\n",
       "9798  5d9cb4f22358f20614262617  513e64e8c9fda01d49792dc7a25f1810   \n",
       "9799  5d9cb4f22358f20614262618  fd9de0cc46acc434d7ac9db53f7dff25   \n",
       "9800  5d9cb4f22358f20614262619  82fd14bdbacb142f370d4c9f46bd00dc   \n",
       "9801  5d9cb4f22358f2061426261a  ff7435b4b80a6d4ea5f9c384248a4997   \n",
       "9802  5d9cb4f22358f2061426261b  01afc3ca99156fdf7da380154483e7dc   \n",
       "\n",
       "                                                  preds  \\\n",
       "9798                                               dota   \n",
       "9799  some of the most memorable SpongeBob SquarePan...   \n",
       "9800        commenting on towers, Roshan and hero picks   \n",
       "9801                make a comment on his love of money   \n",
       "9802  adding some of the most memorable SpongeBob Sq...   \n",
       "\n",
       "                              preds_id  \\\n",
       "9798  9373295a57fc51bab0afc62ee2c763e3   \n",
       "9799  e6c7ab712ea812ce5b5b69b60611e3bf   \n",
       "9800  e3e1f28da0456db79291e84d77a5ae0a   \n",
       "9801  adbeb42e531f3760095e017d026c0df8   \n",
       "9802  1f53d0d56c593ba266643310dc867821   \n",
       "\n",
       "                                          preds_raw_int  \\\n",
       "9798                                    [103, 17, 9, 1]   \n",
       "9799  [128, 13, 8, 167, 10080, 2526, 2444, 15, 279, ...   \n",
       "9800  [1670, 53, 30, 7293, 7, 6, 7963, 2618, 11, 160...   \n",
       "9801        [143, 3, 9, 1670, 30, 112, 333, 13, 540, 1]   \n",
       "9802  [2651, 128, 13, 8, 167, 10080, 2526, 2444, 15,...   \n",
       "\n",
       "                                          preds_raw_str  preds_raw_count  \\\n",
       "9798                                  ['▁do', 't', 'a']                3   \n",
       "9799  ['▁some', '▁of', '▁the', '▁most', '▁memorable'...               15   \n",
       "9800  ['▁comment', 'ing', '▁on', '▁tower', 's', ',',...               13   \n",
       "9801  ['▁make', '▁', 'a', '▁comment', '▁on', '▁his',...                9   \n",
       "9802  ['▁adding', '▁some', '▁of', '▁the', '▁most', '...               16   \n",
       "\n",
       "      truncated  score_proba  \\\n",
       "9798          1     0.495587   \n",
       "9799          1     0.541317   \n",
       "9800          1     0.254643   \n",
       "9801          1     0.557354   \n",
       "9802          1     0.692029   \n",
       "\n",
       "                                       preds_raw_scores  \n",
       "9798  [0.5015457272529602, 0.9999641180038452, 0.999...  \n",
       "9799  [0.671987771987915, 0.9991242289543152, 0.9999...  \n",
       "9800  [0.42295578122138977, 0.9977735877037048, 0.98...  \n",
       "9801  [0.7199561595916748, 0.9998311996459961, 0.999...  \n",
       "9802  [0.9828467965126038, 0.9836350679397583, 0.999...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f529c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
