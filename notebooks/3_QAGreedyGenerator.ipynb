{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f349d70",
   "metadata": {},
   "source": [
    "# 3. Scores Generator (A)\n",
    "\n",
    "We have divided this notebook into the following parts:\n",
    "\n",
    "1. Load **matrix**: We load a CSV file with the preprocessed matrix. \n",
    "2. Load **model**: Using hugging face API, we load a pre-trained or a fine-tuned model and apply it to the said matrix to obtain corresponding predictions.\n",
    "\n",
    "3. **Model-specific preprocessing**: We apply model specific fine-tuning that is related with how the models were trained to encode the strings.\n",
    "3. Create **preds**: We create a CSV file with the predictions concerning the model to evaluate.\n",
    "\n",
    "**Note**: We assume that all matrices have a set of `ID_COLS` that uniquely identifies each row. Additionally, for multi-way (or multi-annotated) datasets, we assume a row-wise format, that is, all the necessary data has already been unrolled  along the first dimension. For example, let us consider a __source dataset__ with $200$ examples, where each of them comprises two different annotations. This notebook __assumes that dataset was previously preprocessed__ and is __now unflattened__ totalling $400$ rows (one per example and annotation) when loaded from memory. While this duplicates memory, it avoids having complex pipelines with intrinsic hand-tailored routines for each dataset (i.e., _bye bye spaghetti_ code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3173c1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using example_id as the unique column to de-duplicate the data\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = \"../outputs\"\n",
    "!mkdir -p {OUTPUT_DIR}\n",
    "\n",
    "ROOT_DIR = f\"{OUTPUT_DIR}/results/mocha/narrativeqa/dev4\"\n",
    "!mkdir -p {ROOT_DIR}\n",
    "\n",
    "# TODO - Come up with some uuid (model_name + dataset + split)\n",
    "MATRIX_FILEPATH = f\"{ROOT_DIR}/matrix/dev4-uqa-t5-small_preds.csv.gz\"\n",
    "\n",
    "# Outputs\n",
    "PREDS_FILEPATH = f\"{ROOT_DIR}/preds/dev4-uqa-t5-small_preds.csv.gz\"\n",
    "!mkdir -p {ROOT_DIR}/preds\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "# Arguments used to read the files from disk\n",
    "csv_kwargs = {\n",
    "   \"compression\": \"gzip\"\n",
    "}\n",
    "\n",
    "# ----------------------------------------\n",
    "## Columns names\n",
    "# ----------------------------------------\n",
    "ID_COLS = [\"example_id\", \"answer_id\"]\n",
    "\n",
    "UNIQUE_ID_COL = ID_COLS[0]\n",
    "NON_UNIQUE_ID_COL = ID_COLS[1]\n",
    "print(\"Using\", UNIQUE_ID_COL, \"as the unique column to de-duplicate the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e39fac",
   "metadata": {},
   "source": [
    "## Load matrix \n",
    "\n",
    "This is the preprocessed matrix that will be used by every model when creating predictions. We expect it to  have the following columns:\n",
    "- `ID_COLS: List[str]`, can be one or more set of unique identifier columns.\n",
    "- `TOPIC: str`, optional, provides a high-level categorization of the different examples.\n",
    "\n",
    "- Dataset specific columns, such as `CONTEXT`, `QUESTION`, `ANSWER` for open-book (closed-domain) QA tasks. Amongst these we usually define the `TARGET_LABEL` and the `FEATURES` the ones that will be encoded together for generative purposes.\n",
    "\n",
    "\n",
    "By default we will assume the following columns:\n",
    "- `TARGET_LABEL = 'label'`\n",
    "- `FEATURES = ['question', 'context']`\n",
    "\n",
    "\n",
    "**Note**: ~~May have to reconsider the use of pandas, for larger datasets, since it wont be feasible to hold them in memory. Instead, may consider HuggingFace `datasets` or `pyspark`.~~ Consider [building script](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-or-remote-files) in case more demanding needs arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60de8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd48ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LABEL = \"label\"\n",
    "FEATURES = [\"question\", \"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dff899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-93e3039272822da3\n",
      "Reusing dataset csv (/home/kat/.cache/huggingface/datasets/csv/default-93e3039272822da3/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354f9ab4ab77482bab9c09e2a3edd7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 445 datapoints from ../outputs/results/mocha/narrativeqa/dev4/matrix/dev4-uqa-t5-small_preds.csv.gz\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "matrix = datasets.load_dataset('csv', data_files=MATRIX_FILEPATH)[\"train\"]\n",
    "print(\"Loaded\", len(matrix), \"datapoints from\", MATRIX_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd895cf5",
   "metadata": {},
   "source": [
    "### Remove duplicate entries when generating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9aca1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/kat/.cache/huggingface/datasets/csv/default-93e3039272822da3/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e/cache-c622453c434803da.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining 277 datapoints after dropping duplicates\n"
     ]
    }
   ],
   "source": [
    "def drop_duplicates(data, col):\n",
    "    unique_col_values = {k: True for k in data.unique(col)}\n",
    "    return data.filter(lambda example: unique_col_values.pop(example[col], False))\n",
    "\n",
    "matrix = drop_duplicates(matrix, UNIQUE_ID_COL)\n",
    "print(\"Remaining\", len(matrix), \"datapoints after dropping duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d440a",
   "metadata": {},
   "source": [
    "## Load model\n",
    "\n",
    "Using HF's API, we load a pre-trained or a fine-tuned model and apply it to the said matrix to obtain corresponding predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b036ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"allenai/unifiedqa-t5-small\"\n",
    "model_name = \"t5-small\"\n",
    "model_hf_kwargs = {\n",
    "    # Path to directory to store the pretrained models\n",
    "    # (may make ensuing analysis faster)\n",
    "    \"cache_dir\": f\"{OUTPUT_DIR}/model/cache\",\n",
    "    # Specific version of the model to use (defaults to main)\n",
    "    # \"revision\": \"main\",\n",
    "}\n",
    "\n",
    "model_hyperparameters = {\n",
    "    \"padding\": \"max_length\",\n",
    "    \"max_length\": 512,\n",
    "    \n",
    "    \"truncation\": True,\n",
    "    \"add_special_tokens\": True,\n",
    "    \"return_attention_mask\": True,\n",
    "    \"target_max_length\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2634637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from utils_generic import filter_params, filter_params_by_prefix\n",
    "\n",
    "import logging\n",
    "import transformers\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class T5Model:\n",
    "    model_name: str\n",
    "    model_hyperparameters: dict\n",
    "        \n",
    "    model_hf_kwargs: dict = field(default_factory=dict)\n",
    "    _tokenizer = None\n",
    "    _model = None\n",
    "        \n",
    "    def _format_row(self, row, features):\n",
    "        prefixes = [f\"{f}: {row[f]}\" for f in features]\n",
    "        sep = f\" {self._tokenizer.eos_token} \"\n",
    "        return {\"encoded\": sep.join(prefixes)}\n",
    "\n",
    "    def encode(self, data, target_label, prefix: str = None):\n",
    "        if prefix is None:\n",
    "            hyperparams = self.model_hyperparameters\n",
    "        else:\n",
    "            hyperparams = filter_params_by_prefix(self.model_hyperparameters, prefix)\n",
    "        \n",
    "        hyperparams = filter_params(hyperparams, self._tokenizer)\n",
    "        logging.warning(f\"Using {hyperparams} to encode (target={target_label}, prefix={prefix}): {hyperparams}\")\n",
    "        return self._tokenizer(data[target_label], **hyperparams)\n",
    "        \n",
    "    def load(self):\n",
    "        # Configuration (defines vocab size, model dimensions, ...)\n",
    "        # config = transformers.T5Config.from_pretrained(\n",
    "        #    model_name, **kwargs)\n",
    "        # ^ Note:\n",
    "        # Changes in T5 configurations should be done here:\n",
    "        # ...\n",
    "        tokenizer_fn = transformers.T5TokenizerFast.from_pretrained\n",
    "        tokenizer_params = filter_params(self.model_hf_kwargs, tokenizer_fn)\n",
    "        self._tokenizer = tokenizer_fn(self.model_name, **tokenizer_params)\n",
    "\n",
    "        model_fn = transformers.T5ForConditionalGeneration.from_pretrained\n",
    "        model_params = filter_params(self.model_hf_kwargs, model_fn)\n",
    "        self._model = model_fn(self.model_name, **model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b57ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5Model(model_name, model_hyperparameters, model_hf_kwargs)\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81cc15",
   "metadata": {},
   "source": [
    "## Generate predictions\n",
    "Using the model and the preprocessed matrix, generate the predictions. \n",
    "The predictions files will contain the following information:\n",
    "\n",
    "- `example_id`: the id of the example used when making the prediction.\n",
    "- `score_proba: float`, a probability value that corresponds to the generated answer up until the `EOS` (end-of-sequence) token.\n",
    "- `preds: str`, a textual description of the decoded model answers (after prediction).\n",
    "- `preds_token_ids: List[int]`: a list with the generated tokens ids.\n",
    "- `preds_token_score_proba: List[float]`: a list with the (conditional) probability generated for each token in the sequence.\n",
    "\n",
    "\n",
    "Useful resources:\n",
    "- [dataset and Pytorch](https://huggingface.co/docs/datasets/use_dataset.html)\n",
    "- [fine-tuning a pretrained model](https://huggingface.co/course/chapter3/4?fw=pt)\n",
    "- [generator](https://huggingface.co/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.generation_utils.GreedySearchDecoderOnlyOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6933a7fc",
   "metadata": {},
   "source": [
    "### Model-tailored Preprocessing\n",
    "\n",
    "We apply model specific fine-tuning that is related with how the models were trained to encode the strings. We will apply this on a per-batch basis to avoid additional overhead in iterating the datasets. We use the [`datasets.Dataset.set_format`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.set_format) as a more efficient way to cast the necessary columns to pytorch structures. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4634dec",
   "metadata": {},
   "source": [
    "### Creating Predictions\n",
    "\n",
    "We want to be able to create predictions both for `Beam search` and for `greedy search`. We will focus for now in the case when we have a single return sequence (even though we can have multiple beams or multiple paths explored).\n",
    "\n",
    "A predictions matrix will have the following attributes/columns:\n",
    "- `ID_COLUMNS`: ideally comprised of the unique identifier \n",
    "- `pred_uuid`: unique identifier for each example (computed for each instance based on the model_uuid and the generated tokens).\n",
    "- `score_proba`: score associated with the generated sentence. computed as the multiplication of the individual raw_scores. the score is within $[0, 1]$.\n",
    "- `preds`: textual representation of the generated instance\n",
    "- `preds_raw_int`: tokens id \n",
    "- `preds_raw_str`: tokens str\n",
    "- `preds_raw_scores`: scores for each of the tokens, lie in the range $[0, 1]$.\n",
    "- `len`: length of the sentence\n",
    "- `truncated`: whether the sequence was truncated (i.e., actually had the eos token).\n",
    "\n",
    "Similarly to the implementation of [lm-calibration](https://github.com/jzbjyb/lm-calibration/blob/887e3e13df0462842ce288fffe588e549a3360ee/model/gpt2.py#L67) we apply log-softmax to the log-probabilities before summing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cfe905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREEDY_KWARGS = {\n",
    "    \"num_beams\": 1,\n",
    "    \"do_sample\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2ff9ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1295d5e3c984d1f803a8a96aacd3eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266bae710938456a8796fe71cea10b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True} to encode (target=encoded, prefix=None): {'padding': 'max_length', 'max_length': 512, 'truncation': True, 'add_special_tokens': True, 'return_attention_mask': True}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "batch_preds = defaultdict(list)\n",
    "\n",
    "batch = matrix\n",
    "batch = batch.map(model._format_row, fn_kwargs={\"features\": FEATURES})\n",
    "batch = batch.map(lambda examples: model.encode(examples, 'encoded'), batched=True)\n",
    "batch.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"], output_all_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6ec9d3",
   "metadata": {},
   "source": [
    "### Greedy results \n",
    "\n",
    "In the case you're using a T5-like or BART-like model, the output of the call below will be a [GreedySearchEncoderDecoderOutput](https://huggingface.co/docs/transformers/internal/generation_utils#transformers.generation_utils.GreedySearchEncoderDecoderOutput). According to the documentation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a34a70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_id</th>\n",
       "      <th>preds_raw_int</th>\n",
       "      <th>preds_raw_str</th>\n",
       "      <th>preds_raw_count</th>\n",
       "      <th>truncated</th>\n",
       "      <th>score_proba</th>\n",
       "      <th>preds_raw_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e6b688ad84546d681f1339df539a0b2</td>\n",
       "      <td>618baa6d3449a6d9171cd39bf204e8c9</td>\n",
       "      <td>doctor pascal rougon</td>\n",
       "      <td>abe46eacce04f58879f56150c248564d</td>\n",
       "      <td>[2472, 330, 1489, 3, 3964, 5307, 1]</td>\n",
       "      <td>[▁doctor, ▁pas, cal, ▁, rou, gon]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.444278</td>\n",
       "      <td>[0.45619308948516846, 0.9993246793746948, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2aea58b6733f531e127a96752d9db1a4</td>\n",
       "      <td>52e62d271a8dbbc887e25f68681794b4</td>\n",
       "      <td>converts</td>\n",
       "      <td>88a6dc645c7d491d08aece45c8eaca71</td>\n",
       "      <td>[5755, 7, 1]</td>\n",
       "      <td>[▁convert, s]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.685860</td>\n",
       "      <td>[0.8886101841926575, 0.9971410036087036, 0.774...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a9bf0ee9eac598663c3f2c9a9908b1e6</td>\n",
       "      <td>2093f3df3379e16364141294a8c9a062</td>\n",
       "      <td>into a \"swimming tank\"</td>\n",
       "      <td>4e6598f9b608b3f532f4f1e537e461a8</td>\n",
       "      <td>[139, 3, 9, 96, 7, 210, 23, 635, 53, 5040, 121...</td>\n",
       "      <td>[▁into, ▁, a, ▁\", s, w, i, mm, ing, ▁tank, \"]</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.549538</td>\n",
       "      <td>[0.7651849389076233, 0.9803006052970886, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f485d3509a0606a7b570cc5f2edbd083</td>\n",
       "      <td>e2fd235719de9140057fdb4e61e930e9</td>\n",
       "      <td>a competition of \"court compliment\"</td>\n",
       "      <td>36bbc8a0cef5d357cacd366611cc23cf</td>\n",
       "      <td>[3, 9, 2259, 13, 96, 14492, 12064, 121, 1]</td>\n",
       "      <td>[▁, a, ▁competition, ▁of, ▁\", court, ▁complime...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.397013</td>\n",
       "      <td>[0.45407775044441223, 0.9586190581321716, 0.97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>921d4e8c8c14e3b385bb80546b792154</td>\n",
       "      <td>8266b87c9f4982b8d7ed33efba54537b</td>\n",
       "      <td>a gypsy boy, pablo</td>\n",
       "      <td>6a2bcdc69999a8d9394ff25f86d6580e</td>\n",
       "      <td>[3, 9, 3, 122, 63, 19819, 4940, 6, 2576, 4672, 1]</td>\n",
       "      <td>[▁, a, ▁, g, y, psy, ▁boy, ,, ▁pa, blo]</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159552</td>\n",
       "      <td>[0.6082004308700562, 0.5329281687736511, 0.945...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bdd61f9bb3f8781f37190f4c671320a3</td>\n",
       "      <td>5e82884a83521fa2ebd1b6cc95a4b14a</td>\n",
       "      <td>wounding herself mortally with a rifle</td>\n",
       "      <td>8c11d545467e2d0b65e00c013ca80cb9</td>\n",
       "      <td>[9699, 53, 6257, 24301, 120, 28, 3, 9, 18371, 1]</td>\n",
       "      <td>[▁wound, ing, ▁herself, ▁mortal, ly, ▁with, ▁,...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.128462</td>\n",
       "      <td>[0.1338125765323639, 0.986093282699585, 0.9979...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5c7966bb9f9aea98baf2b9523776f82b</td>\n",
       "      <td>9b983e2910f05fe7597787f8e0faf4f2</td>\n",
       "      <td>suicide</td>\n",
       "      <td>24af5c17e5ba8954f17a98806458889a</td>\n",
       "      <td>[12259, 1]</td>\n",
       "      <td>[▁suicide]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.231917</td>\n",
       "      <td>[0.2435421347618103, 0.9522663950920105]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ad4563df309a58f9affa2cd854a0ce0e</td>\n",
       "      <td>2e85cb5ca4286f3cbfd589cf587cf9bd</td>\n",
       "      <td>he takes his orders and becomes the parish pri...</td>\n",
       "      <td>aa8433cd5f28980726dab95cccd6f010</td>\n",
       "      <td>[3, 88, 1217, 112, 5022, 11, 2992, 8, 14961, 1...</td>\n",
       "      <td>[▁, he, ▁takes, ▁his, ▁orders, ▁and, ▁becomes,...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031928</td>\n",
       "      <td>[0.1293245106935501, 0.5078274011611938, 0.674...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b9756df13b1b7963dc0b507dfa5297a2</td>\n",
       "      <td>772a657a23d1613e49036fa98549a39f</td>\n",
       "      <td>gets himself expelled from cambridge after att...</td>\n",
       "      <td>7e1c3d68eb5c86149f40adcbac0f70da</td>\n",
       "      <td>[2347, 2448, 1215, 14528, 45, 5511, 9818, 227,...</td>\n",
       "      <td>[▁gets, ▁himself, ▁ex, pelled, ▁from, ▁cam, br...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580548</td>\n",
       "      <td>[0.671929121017456, 0.996823787689209, 0.99861...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a0491b138fb1f9b4dbc1c4eee651c922</td>\n",
       "      <td>57bdce5ad3ce730e7d074358eb971e1a</td>\n",
       "      <td>attending the derby without permission</td>\n",
       "      <td>c24a004b9c7ed44b15bf356cd9252ea3</td>\n",
       "      <td>[7078, 8, 74, 969, 406, 6059, 1]</td>\n",
       "      <td>[▁attending, ▁the, ▁der, by, ▁without, ▁permis...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144703</td>\n",
       "      <td>[0.19296632707118988, 0.9960280656814575, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fb22016ae6d01cc81010b10a52368e51</td>\n",
       "      <td>0f8c9a3f3d0ef5931264d91ab4ba706c</td>\n",
       "      <td>malta</td>\n",
       "      <td>1f6822bd24db8b72f47b4507e7630d08</td>\n",
       "      <td>[1460, 17, 9, 1]</td>\n",
       "      <td>[▁mal, t, a]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644998</td>\n",
       "      <td>[0.6620191931724548, 0.9785651564598083, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6a1962b5dbe9a81cb75bb07dbf5669ef</td>\n",
       "      <td>e9ae37f4295ebdd6784bee441be81df4</td>\n",
       "      <td>numedides</td>\n",
       "      <td>17fc43082faf8aabee559846ad76a515</td>\n",
       "      <td>[7507, 26, 9361, 1]</td>\n",
       "      <td>[▁nume, d, ides]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995102</td>\n",
       "      <td>[0.9992285966873169, 0.999927282333374, 0.9999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1a1d261030142098c1bfeb7cb89d796e</td>\n",
       "      <td>5ef799ab36e56957ee6cb47ed2b7d47b</td>\n",
       "      <td>edward</td>\n",
       "      <td>d55d2e966996b2fec0cb2ddbfc05cc58</td>\n",
       "      <td>[3, 15, 26, 2239, 1]</td>\n",
       "      <td>[▁, e, d, ward]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>[0.988783061504364, 0.9949404001235962, 0.9999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>675936324cb453372def083ee268e7ca</td>\n",
       "      <td>f8f5f8da83093b4a291abc0328431a00</td>\n",
       "      <td>the gods cupid and mercury</td>\n",
       "      <td>2a74400ce0e06870974c2729e35ac2a0</td>\n",
       "      <td>[8, 8581, 7, 123, 12417, 11, 29991, 1]</td>\n",
       "      <td>[▁the, ▁god, s, ▁cu, pid, ▁and, ▁mercury]</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.199961</td>\n",
       "      <td>[0.5570692420005798, 0.7717386484146118, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6c997568ebc04309f40e5d17985ef121</td>\n",
       "      <td>9e03b10f369f58463c868fc2841a5b1f</td>\n",
       "      <td>raphael</td>\n",
       "      <td>b1107c860295adc8490572d5dcbd049c</td>\n",
       "      <td>[3, 5846, 1024, 15, 40, 1]</td>\n",
       "      <td>[▁, rap, ha, e, l]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817120</td>\n",
       "      <td>[0.8455095291137695, 0.9790767431259155, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0b10471c6be838c4ee75c9bd9ef4a4d9</td>\n",
       "      <td>bd0b8f73112b68efcd6fa591d645d83e</td>\n",
       "      <td>vivie is romantically involved with the youthf...</td>\n",
       "      <td>f27b126a9a9acf570192df8c134b19ff</td>\n",
       "      <td>[5931, 5914, 19, 7966, 1427, 1381, 28, 8, 2669...</td>\n",
       "      <td>[▁vi, vie, ▁is, ▁romantic, ally, ▁involved, ▁w...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.206347</td>\n",
       "      <td>[0.4402723014354706, 0.9986995458602905, 0.492...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9eaf24558e2334d59a64b4c35179356a</td>\n",
       "      <td>7078b1145bdd701cee0a07b47428dfb2</td>\n",
       "      <td>amnesia</td>\n",
       "      <td>cf99faad89b1684f8eb5db3968edf8ea</td>\n",
       "      <td>[183, 1496, 23, 9, 1]</td>\n",
       "      <td>[▁am, nes, i, a]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507416</td>\n",
       "      <td>[0.7028640508651733, 0.999924898147583, 0.9994...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>685c78575e46b145046aa3cbb59c17d7</td>\n",
       "      <td>d4ab3d38299137c7690c7269a27e97d8</td>\n",
       "      <td>orestes</td>\n",
       "      <td>5fc05cb11d00740b2a358875fc24d993</td>\n",
       "      <td>[42, 2613, 7, 1]</td>\n",
       "      <td>[▁or, este, s]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.873690</td>\n",
       "      <td>[0.8847248554229736, 0.9998818635940552, 0.993...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9056a53de46005e6cc102b288a2516cd</td>\n",
       "      <td>1c2a6083f587b739225c1ca302831b0f</td>\n",
       "      <td>echo</td>\n",
       "      <td>6894a43d14a7855679c232fb57019643</td>\n",
       "      <td>[20747, 1]</td>\n",
       "      <td>[▁echo]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872898</td>\n",
       "      <td>[0.8892452716827393, 0.9816162586212158]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>b62fa1e5d738193093b6e248c9938013</td>\n",
       "      <td>ca45816df3c21cd667f5381fe0bb3aad</td>\n",
       "      <td>in his isolated cottage</td>\n",
       "      <td>5688a77c364cb81391157d098414504e</td>\n",
       "      <td>[16, 112, 12996, 12268, 1]</td>\n",
       "      <td>[▁in, ▁his, ▁isolated, ▁cottage]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.272569</td>\n",
       "      <td>[0.29214540123939514, 0.9823294281959534, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2ba5107606bc69bc431795d5c9302d18</td>\n",
       "      <td>79bfe4f7e5801c2741eb5908791851fd</td>\n",
       "      <td>the duke be informed</td>\n",
       "      <td>04ec7577e4b191b5b55c56fba3ad309f</td>\n",
       "      <td>[8, 146, 1050, 36, 4862, 1]</td>\n",
       "      <td>[▁the, ▁du, ke, ▁be, ▁informed]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.244704</td>\n",
       "      <td>[0.43049895763397217, 0.8131089806556702, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>35d77183dca9adb82a37c5a9a8c59c63</td>\n",
       "      <td>1d977301a1a140208e439ea2e8bb3df8</td>\n",
       "      <td>across europe</td>\n",
       "      <td>7abf2a625b5ccd2445badd9e31f8d174</td>\n",
       "      <td>[640, 3, 28188, 1]</td>\n",
       "      <td>[▁across, ▁, europe]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939584</td>\n",
       "      <td>[0.9418609142303467, 0.9989416003227234, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>d78874758c77326513cb59b717c6b7e4</td>\n",
       "      <td>8da76dbea5ef2996f56dd230ac3aad4d</td>\n",
       "      <td>scarlet citadel</td>\n",
       "      <td>085c76710186808e951cfc3bc5dfe2ba</td>\n",
       "      <td>[6541, 1655, 6895, 15311, 1]</td>\n",
       "      <td>[▁scar, let, ▁cit, adel]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499267</td>\n",
       "      <td>[0.5013013482093811, 0.9998759031295776, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>e2228447f8bae08d874b1cfd3ced74a0</td>\n",
       "      <td>6f7332f92a82ab6f22b2a46dc85aa940</td>\n",
       "      <td>to win her love</td>\n",
       "      <td>f23802e019e0856de4db70cd22921d86</td>\n",
       "      <td>[12, 1369, 160, 333, 1]</td>\n",
       "      <td>[▁to, ▁win, ▁her, ▁love]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.845291</td>\n",
       "      <td>[0.8542860150337219, 0.9976438879966736, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0ac5ac3d66bca65450678749ba98039b</td>\n",
       "      <td>648e5d7bb0262dc6363762dff2f4777e</td>\n",
       "      <td>valerius</td>\n",
       "      <td>43c60e4412bd2c4f4f99eb63eb9ca926</td>\n",
       "      <td>[409, 109, 18956, 1]</td>\n",
       "      <td>[▁va, le, rius]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956286</td>\n",
       "      <td>[0.9584904909133911, 0.9999479055404663, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>487ef34a89982e8d5ebdecdb2eb93df1</td>\n",
       "      <td>ca364026b219e6a09e50a4ec701fccff</td>\n",
       "      <td>gives serge time to contemplate religious affa...</td>\n",
       "      <td>a0cf7b1b2b7bc27152d61fdad6b62f12</td>\n",
       "      <td>[1527, 7637, 397, 97, 12, 14017, 15, 4761, 127...</td>\n",
       "      <td>[▁gives, ▁ser, ge, ▁time, ▁to, ▁contemplat, e,...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135798</td>\n",
       "      <td>[0.22910034656524658, 0.7027128338813782, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3d09ec61046213dfab25d02cba7969fb</td>\n",
       "      <td>9e26641e03a4f00f6af13e48e76e085c</td>\n",
       "      <td>he takes his orders and becomes the parish pri...</td>\n",
       "      <td>aa8433cd5f28980726dab95cccd6f010</td>\n",
       "      <td>[3, 88, 1217, 112, 5022, 11, 2992, 8, 14961, 1...</td>\n",
       "      <td>[▁, he, ▁takes, ▁his, ▁orders, ▁and, ▁becomes,...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035583</td>\n",
       "      <td>[0.19860149919986725, 0.6356847286224365, 0.42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>c0ebdb22514d4a6bdf2e75dfa918f0ee</td>\n",
       "      <td>0009a2a7aa6d6eeafb62cd11ab0748e9</td>\n",
       "      <td>amnesia</td>\n",
       "      <td>cf99faad89b1684f8eb5db3968edf8ea</td>\n",
       "      <td>[183, 1496, 23, 9, 1]</td>\n",
       "      <td>[▁am, nes, i, a]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524897</td>\n",
       "      <td>[0.9556050300598145, 0.9999589920043945, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>d68a5e4efd8df22f539345dc4729ad19</td>\n",
       "      <td>91aaec096df2acf78159670a6e9eaf19</td>\n",
       "      <td>to prevent the accused from hearing what is be...</td>\n",
       "      <td>ec05efa5dc036fb8eba68ba33b0bbeed</td>\n",
       "      <td>[12, 1709, 8, 11970, 45, 3507, 125, 19, 1187, ...</td>\n",
       "      <td>[▁to, ▁prevent, ▁the, ▁accused, ▁from, ▁hearin...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222488</td>\n",
       "      <td>[0.29350370168685913, 0.9497087001800537, 0.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>785a3d34c1e89027555b22cf2e5995ad</td>\n",
       "      <td>f711e187712788fadc9f5d2740ea0592</td>\n",
       "      <td>to make reparation and to purify themselves by...</td>\n",
       "      <td>95d6739648e1650640dfef2871a33798</td>\n",
       "      <td>[12, 143, 12243, 257, 11, 12, 3990, 4921, 1452...</td>\n",
       "      <td>[▁to, ▁make, ▁repar, ation, ▁and, ▁to, ▁pur, i...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375621</td>\n",
       "      <td>[0.5159768462181091, 0.9927565455436707, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>383d556f564deaff1e3073843df9bc2b</td>\n",
       "      <td>6446651bcd655ddc4ce2370a67231f35</td>\n",
       "      <td>pagan philosopher</td>\n",
       "      <td>b225d7f451b7da523bfb641c4fb5c3e4</td>\n",
       "      <td>[2576, 2565, 25857, 1]</td>\n",
       "      <td>[▁pa, gan, ▁philosopher]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.469371</td>\n",
       "      <td>[0.47555890679359436, 0.9999902248382568, 0.98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>c6a7860b55fc807f1463853df4f37b8d</td>\n",
       "      <td>f2b8a8b4e9ddc271ed73da1b793e60c3</td>\n",
       "      <td>dick forrest</td>\n",
       "      <td>35632daa0a9bd7f59515a1076a65d828</td>\n",
       "      <td>[3, 26, 3142, 21, 6216, 1]</td>\n",
       "      <td>[▁, d, ick, ▁for, rest]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.565650</td>\n",
       "      <td>[0.5787684917449951, 0.9824212193489075, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bf5fa100bfab59c7b89244eacf75013d</td>\n",
       "      <td>b276a372f4074203c91b68354273785d</td>\n",
       "      <td>\"grow dotingly enamored of</td>\n",
       "      <td>caaaa91a27dcec59149b94dc6553e0fc</td>\n",
       "      <td>[96, 122, 3623, 103, 1222, 120, 3, 35, 9, 3706...</td>\n",
       "      <td>[▁\", g, row, ▁do, ting, ly, ▁, en, a, more, d,...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.863766</td>\n",
       "      <td>[0.8664252758026123, 0.9995844960212708, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5ea9c499592df5de7cccb7d71648ef74</td>\n",
       "      <td>2c190d49e1163f3fb3ed212e7e87170d</td>\n",
       "      <td>colonel beverley</td>\n",
       "      <td>1d1e71b8573647b72e3b14b5f118f5d5</td>\n",
       "      <td>[6718, 15, 40, 36, 624, 1306, 1]</td>\n",
       "      <td>[▁colon, e, l, ▁be, ver, ley]</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812355</td>\n",
       "      <td>[0.8338054418563843, 0.9998393058776855, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>d0b7b2732e5c5127662e690bdc5c37b2</td>\n",
       "      <td>e4b87e77185b82d07bf0b3ea48a66b7d</td>\n",
       "      <td>courtiers and ladies</td>\n",
       "      <td>11df44f1b07ecd92b6bf76c86161526c</td>\n",
       "      <td>[1614, 4518, 11, 10989, 1]</td>\n",
       "      <td>[▁court, iers, ▁and, ▁ladies]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.369390</td>\n",
       "      <td>[0.43628817796707153, 0.9973414540290833, 0.97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>cfd4d007bea19ecc0375afafc0e89205</td>\n",
       "      <td>f3950f5c35604d9fb80f5cc7e52f1e67</td>\n",
       "      <td>serge monstrous former monseignor</td>\n",
       "      <td>f8b20a9e36543c3c5116c1975b1580d1</td>\n",
       "      <td>[7637, 397, 1911, 6626, 302, 1798, 1911, 7, 15...</td>\n",
       "      <td>[▁ser, ge, ▁mon, stro, us, ▁former, ▁mon, s, e...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.129434</td>\n",
       "      <td>[0.5341707468032837, 0.8531247973442078, 0.338...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>e147946772e9c1303f37d50a6a3de64f</td>\n",
       "      <td>2b3045eb5ef281cdc9d7aa9258245640</td>\n",
       "      <td>poisoned</td>\n",
       "      <td>e743019b96626ebde90aad204e1a7401</td>\n",
       "      <td>[14566, 15, 26, 1]</td>\n",
       "      <td>[▁poison, e, d]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292247</td>\n",
       "      <td>[0.3425084054470062, 0.9881272912025452, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7c2db16d04b67b4f834e5293481f5687</td>\n",
       "      <td>0f84fcb67e34f92ef2408136e604811d</td>\n",
       "      <td>if the duke is willing to welcome her into the</td>\n",
       "      <td>2e467997bf247acf54d5ea84341cfa0f</td>\n",
       "      <td>[3, 99, 8, 146, 1050, 19, 4403, 12, 2222, 160,...</td>\n",
       "      <td>[▁, if, ▁the, ▁du, ke, ▁is, ▁willing, ▁to, ▁we...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.244028</td>\n",
       "      <td>[0.6225618124008179, 0.425942987203598, 0.9718...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3ff65ba05e423684016b98f427f5c796</td>\n",
       "      <td>e6da694e22f0cc2943bec6fd92fa32e4</td>\n",
       "      <td>he challenges all comers to a competition of</td>\n",
       "      <td>fe5f061a600cb6775207ac3a43dd28d1</td>\n",
       "      <td>[3, 88, 2428, 66, 3, 287, 277, 12, 3, 9, 2259,...</td>\n",
       "      <td>[▁, he, ▁challenges, ▁all, ▁, com, ers, ▁to, ▁...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.281100</td>\n",
       "      <td>[0.309281587600708, 0.9353982210159302, 0.9929...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3a82aaa41611244f4b35f70e4830851b</td>\n",
       "      <td>a5cb361aa0f9ec2d658c0e8e414488e6</td>\n",
       "      <td>nemedia</td>\n",
       "      <td>484931a9c4d643247cb8241366199734</td>\n",
       "      <td>[3, 29, 15, 8172, 1]</td>\n",
       "      <td>[▁, n, e, media]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.552084</td>\n",
       "      <td>[0.8192062973976135, 0.995919942855835, 0.9999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8061bcd5dcbb9bc78036b90fd187f753</td>\n",
       "      <td>7897019973dc94bb756ef70ada05e4d5</td>\n",
       "      <td>mount helicon</td>\n",
       "      <td>cf523a4c0ccf2e84bb3dcaa5808a5bf4</td>\n",
       "      <td>[9549, 3, 17801, 1018, 1]</td>\n",
       "      <td>[▁mount, ▁, heli, con]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.914243</td>\n",
       "      <td>[0.9163744449615479, 0.9995006322860718, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>f3855e66f157831f5314d6d604c19ef0</td>\n",
       "      <td>a15da22ea81e20701325af4b8034bf73</td>\n",
       "      <td>scarlet citadel</td>\n",
       "      <td>085c76710186808e951cfc3bc5dfe2ba</td>\n",
       "      <td>[6541, 1655, 6895, 15311, 1]</td>\n",
       "      <td>[▁scar, let, ▁cit, adel]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.219856</td>\n",
       "      <td>[0.22041581571102142, 0.9998772144317627, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>48f579e6f8f2525f6198936eee191f35</td>\n",
       "      <td>bbd4912c6f1bf30bed96daaaec969079</td>\n",
       "      <td>a person accused of a crime is brought into</td>\n",
       "      <td>dbcc48c3b0b98c77a5775b28195836bb</td>\n",
       "      <td>[3, 9, 568, 11970, 13, 3, 9, 5447, 19, 1940, 1...</td>\n",
       "      <td>[▁, a, ▁person, ▁accused, ▁of, ▁, a, ▁crime, ▁...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109603</td>\n",
       "      <td>[0.3296971619129181, 0.5810139775276184, 0.581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>40d05cf812f0771775541e55366eafc6</td>\n",
       "      <td>20c1995684868fcd4d9a366167b92f9d</td>\n",
       "      <td>in a land ruled by a semi-bar</td>\n",
       "      <td>06b9c94b56af45a7941cc1acfee3201b</td>\n",
       "      <td>[16, 3, 9, 1322, 3, 16718, 57, 3, 9, 4772, 18,...</td>\n",
       "      <td>[▁in, ▁, a, ▁land, ▁, ruled, ▁by, ▁, a, ▁semi,...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341133</td>\n",
       "      <td>[0.3780934810638428, 0.9662409424781799, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>cafc79edd6e4ed59544c66e4d22d01b0</td>\n",
       "      <td>432c0107946d8c87b1a6288ad1e94f0e</td>\n",
       "      <td>serge mouret</td>\n",
       "      <td>b17370777e8f949375c7fca369e7eea1</td>\n",
       "      <td>[7637, 397, 13102, 60, 17, 1]</td>\n",
       "      <td>[▁ser, ge, ▁mou, re, t]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977961</td>\n",
       "      <td>[0.9852861166000366, 0.9996968507766724, 0.997...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>6687badff1cc036f38889d7bbec26d37</td>\n",
       "      <td>05235109843c50237a7995173ca6c07b</td>\n",
       "      <td>both doors are heavily soundproofed to prevent...</td>\n",
       "      <td>b25fb69841375fde97fee16b3582c8b3</td>\n",
       "      <td>[321, 3377, 33, 8672, 1345, 8592, 15, 26, 12, ...</td>\n",
       "      <td>[▁both, ▁doors, ▁are, ▁heavily, ▁sound, proof,...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135646</td>\n",
       "      <td>[0.24964524805545807, 0.9974580407142639, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6d90b243c149d3afd65b5f111e17de81</td>\n",
       "      <td>5b7812299328d8c4e97c95538aa8cfdf</td>\n",
       "      <td>the duke is left bereft of both his</td>\n",
       "      <td>8ebc2ddfd797cc1b0112634d3260489f</td>\n",
       "      <td>[8, 146, 1050, 19, 646, 36, 60, 89, 17, 13, 32...</td>\n",
       "      <td>[▁the, ▁du, ke, ▁is, ▁left, ▁be, re, f, t, ▁of...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.169563</td>\n",
       "      <td>[0.3738134205341339, 0.48040515184402466, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ac3e1c07f443bf8bc9f9c5657c9657cf</td>\n",
       "      <td>b917df1cea646214815412bfb5471a62</td>\n",
       "      <td>execution</td>\n",
       "      <td>e98ff6ad02b97487df562cfd3854a378</td>\n",
       "      <td>[9328, 1]</td>\n",
       "      <td>[▁execution]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.319445</td>\n",
       "      <td>[0.3407576084136963, 0.937455952167511]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2fa7579b281f289a7cba71650ff03494</td>\n",
       "      <td>ec0d2a797ac254967ef2942647c7df5b</td>\n",
       "      <td>university of cambridge</td>\n",
       "      <td>3cf87293fa36531ac683b457770e8fb5</td>\n",
       "      <td>[3819, 13, 5511, 9818, 1]</td>\n",
       "      <td>[▁university, ▁of, ▁cam, bridge]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.546961</td>\n",
       "      <td>[0.5519163012504578, 0.9973983764648438, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>e95b4f9d9bef0308088d854aebf72dfb</td>\n",
       "      <td>d019d1b9852d24c4651daf7e41ee98ef</td>\n",
       "      <td>white</td>\n",
       "      <td>110836b5cd6a64ba8d508d1fb7c6630c</td>\n",
       "      <td>[872, 1]</td>\n",
       "      <td>[▁white]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.650060</td>\n",
       "      <td>[0.9553894400596619, 0.6804133653640747]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          example_id                         answer_id  \\\n",
       "0   2e6b688ad84546d681f1339df539a0b2  618baa6d3449a6d9171cd39bf204e8c9   \n",
       "1   2aea58b6733f531e127a96752d9db1a4  52e62d271a8dbbc887e25f68681794b4   \n",
       "2   a9bf0ee9eac598663c3f2c9a9908b1e6  2093f3df3379e16364141294a8c9a062   \n",
       "3   f485d3509a0606a7b570cc5f2edbd083  e2fd235719de9140057fdb4e61e930e9   \n",
       "4   921d4e8c8c14e3b385bb80546b792154  8266b87c9f4982b8d7ed33efba54537b   \n",
       "5   bdd61f9bb3f8781f37190f4c671320a3  5e82884a83521fa2ebd1b6cc95a4b14a   \n",
       "6   5c7966bb9f9aea98baf2b9523776f82b  9b983e2910f05fe7597787f8e0faf4f2   \n",
       "7   ad4563df309a58f9affa2cd854a0ce0e  2e85cb5ca4286f3cbfd589cf587cf9bd   \n",
       "8   b9756df13b1b7963dc0b507dfa5297a2  772a657a23d1613e49036fa98549a39f   \n",
       "9   a0491b138fb1f9b4dbc1c4eee651c922  57bdce5ad3ce730e7d074358eb971e1a   \n",
       "10  fb22016ae6d01cc81010b10a52368e51  0f8c9a3f3d0ef5931264d91ab4ba706c   \n",
       "11  6a1962b5dbe9a81cb75bb07dbf5669ef  e9ae37f4295ebdd6784bee441be81df4   \n",
       "12  1a1d261030142098c1bfeb7cb89d796e  5ef799ab36e56957ee6cb47ed2b7d47b   \n",
       "13  675936324cb453372def083ee268e7ca  f8f5f8da83093b4a291abc0328431a00   \n",
       "14  6c997568ebc04309f40e5d17985ef121  9e03b10f369f58463c868fc2841a5b1f   \n",
       "15  0b10471c6be838c4ee75c9bd9ef4a4d9  bd0b8f73112b68efcd6fa591d645d83e   \n",
       "16  9eaf24558e2334d59a64b4c35179356a  7078b1145bdd701cee0a07b47428dfb2   \n",
       "17  685c78575e46b145046aa3cbb59c17d7  d4ab3d38299137c7690c7269a27e97d8   \n",
       "18  9056a53de46005e6cc102b288a2516cd  1c2a6083f587b739225c1ca302831b0f   \n",
       "19  b62fa1e5d738193093b6e248c9938013  ca45816df3c21cd667f5381fe0bb3aad   \n",
       "20  2ba5107606bc69bc431795d5c9302d18  79bfe4f7e5801c2741eb5908791851fd   \n",
       "21  35d77183dca9adb82a37c5a9a8c59c63  1d977301a1a140208e439ea2e8bb3df8   \n",
       "22  d78874758c77326513cb59b717c6b7e4  8da76dbea5ef2996f56dd230ac3aad4d   \n",
       "23  e2228447f8bae08d874b1cfd3ced74a0  6f7332f92a82ab6f22b2a46dc85aa940   \n",
       "24  0ac5ac3d66bca65450678749ba98039b  648e5d7bb0262dc6363762dff2f4777e   \n",
       "25  487ef34a89982e8d5ebdecdb2eb93df1  ca364026b219e6a09e50a4ec701fccff   \n",
       "26  3d09ec61046213dfab25d02cba7969fb  9e26641e03a4f00f6af13e48e76e085c   \n",
       "27  c0ebdb22514d4a6bdf2e75dfa918f0ee  0009a2a7aa6d6eeafb62cd11ab0748e9   \n",
       "28  d68a5e4efd8df22f539345dc4729ad19  91aaec096df2acf78159670a6e9eaf19   \n",
       "29  785a3d34c1e89027555b22cf2e5995ad  f711e187712788fadc9f5d2740ea0592   \n",
       "30  383d556f564deaff1e3073843df9bc2b  6446651bcd655ddc4ce2370a67231f35   \n",
       "31  c6a7860b55fc807f1463853df4f37b8d  f2b8a8b4e9ddc271ed73da1b793e60c3   \n",
       "32  bf5fa100bfab59c7b89244eacf75013d  b276a372f4074203c91b68354273785d   \n",
       "33  5ea9c499592df5de7cccb7d71648ef74  2c190d49e1163f3fb3ed212e7e87170d   \n",
       "34  d0b7b2732e5c5127662e690bdc5c37b2  e4b87e77185b82d07bf0b3ea48a66b7d   \n",
       "35  cfd4d007bea19ecc0375afafc0e89205  f3950f5c35604d9fb80f5cc7e52f1e67   \n",
       "36  e147946772e9c1303f37d50a6a3de64f  2b3045eb5ef281cdc9d7aa9258245640   \n",
       "37  7c2db16d04b67b4f834e5293481f5687  0f84fcb67e34f92ef2408136e604811d   \n",
       "38  3ff65ba05e423684016b98f427f5c796  e6da694e22f0cc2943bec6fd92fa32e4   \n",
       "39  3a82aaa41611244f4b35f70e4830851b  a5cb361aa0f9ec2d658c0e8e414488e6   \n",
       "40  8061bcd5dcbb9bc78036b90fd187f753  7897019973dc94bb756ef70ada05e4d5   \n",
       "41  f3855e66f157831f5314d6d604c19ef0  a15da22ea81e20701325af4b8034bf73   \n",
       "42  48f579e6f8f2525f6198936eee191f35  bbd4912c6f1bf30bed96daaaec969079   \n",
       "43  40d05cf812f0771775541e55366eafc6  20c1995684868fcd4d9a366167b92f9d   \n",
       "44  cafc79edd6e4ed59544c66e4d22d01b0  432c0107946d8c87b1a6288ad1e94f0e   \n",
       "45  6687badff1cc036f38889d7bbec26d37  05235109843c50237a7995173ca6c07b   \n",
       "46  6d90b243c149d3afd65b5f111e17de81  5b7812299328d8c4e97c95538aa8cfdf   \n",
       "47  ac3e1c07f443bf8bc9f9c5657c9657cf  b917df1cea646214815412bfb5471a62   \n",
       "48  2fa7579b281f289a7cba71650ff03494  ec0d2a797ac254967ef2942647c7df5b   \n",
       "49  e95b4f9d9bef0308088d854aebf72dfb  d019d1b9852d24c4651daf7e41ee98ef   \n",
       "\n",
       "                                                preds  \\\n",
       "0                                doctor pascal rougon   \n",
       "1                                            converts   \n",
       "2                              into a \"swimming tank\"   \n",
       "3                 a competition of \"court compliment\"   \n",
       "4                                  a gypsy boy, pablo   \n",
       "5              wounding herself mortally with a rifle   \n",
       "6                                             suicide   \n",
       "7   he takes his orders and becomes the parish pri...   \n",
       "8   gets himself expelled from cambridge after att...   \n",
       "9              attending the derby without permission   \n",
       "10                                              malta   \n",
       "11                                          numedides   \n",
       "12                                             edward   \n",
       "13                         the gods cupid and mercury   \n",
       "14                                            raphael   \n",
       "15  vivie is romantically involved with the youthf...   \n",
       "16                                            amnesia   \n",
       "17                                            orestes   \n",
       "18                                               echo   \n",
       "19                            in his isolated cottage   \n",
       "20                               the duke be informed   \n",
       "21                                      across europe   \n",
       "22                                    scarlet citadel   \n",
       "23                                    to win her love   \n",
       "24                                           valerius   \n",
       "25  gives serge time to contemplate religious affa...   \n",
       "26  he takes his orders and becomes the parish pri...   \n",
       "27                                            amnesia   \n",
       "28  to prevent the accused from hearing what is be...   \n",
       "29  to make reparation and to purify themselves by...   \n",
       "30                                  pagan philosopher   \n",
       "31                                       dick forrest   \n",
       "32                         \"grow dotingly enamored of   \n",
       "33                                   colonel beverley   \n",
       "34                               courtiers and ladies   \n",
       "35                  serge monstrous former monseignor   \n",
       "36                                           poisoned   \n",
       "37     if the duke is willing to welcome her into the   \n",
       "38       he challenges all comers to a competition of   \n",
       "39                                            nemedia   \n",
       "40                                      mount helicon   \n",
       "41                                    scarlet citadel   \n",
       "42       a person accused of a crime is brought into    \n",
       "43                      in a land ruled by a semi-bar   \n",
       "44                                       serge mouret   \n",
       "45  both doors are heavily soundproofed to prevent...   \n",
       "46                the duke is left bereft of both his   \n",
       "47                                          execution   \n",
       "48                            university of cambridge   \n",
       "49                                              white   \n",
       "\n",
       "                            preds_id  \\\n",
       "0   abe46eacce04f58879f56150c248564d   \n",
       "1   88a6dc645c7d491d08aece45c8eaca71   \n",
       "2   4e6598f9b608b3f532f4f1e537e461a8   \n",
       "3   36bbc8a0cef5d357cacd366611cc23cf   \n",
       "4   6a2bcdc69999a8d9394ff25f86d6580e   \n",
       "5   8c11d545467e2d0b65e00c013ca80cb9   \n",
       "6   24af5c17e5ba8954f17a98806458889a   \n",
       "7   aa8433cd5f28980726dab95cccd6f010   \n",
       "8   7e1c3d68eb5c86149f40adcbac0f70da   \n",
       "9   c24a004b9c7ed44b15bf356cd9252ea3   \n",
       "10  1f6822bd24db8b72f47b4507e7630d08   \n",
       "11  17fc43082faf8aabee559846ad76a515   \n",
       "12  d55d2e966996b2fec0cb2ddbfc05cc58   \n",
       "13  2a74400ce0e06870974c2729e35ac2a0   \n",
       "14  b1107c860295adc8490572d5dcbd049c   \n",
       "15  f27b126a9a9acf570192df8c134b19ff   \n",
       "16  cf99faad89b1684f8eb5db3968edf8ea   \n",
       "17  5fc05cb11d00740b2a358875fc24d993   \n",
       "18  6894a43d14a7855679c232fb57019643   \n",
       "19  5688a77c364cb81391157d098414504e   \n",
       "20  04ec7577e4b191b5b55c56fba3ad309f   \n",
       "21  7abf2a625b5ccd2445badd9e31f8d174   \n",
       "22  085c76710186808e951cfc3bc5dfe2ba   \n",
       "23  f23802e019e0856de4db70cd22921d86   \n",
       "24  43c60e4412bd2c4f4f99eb63eb9ca926   \n",
       "25  a0cf7b1b2b7bc27152d61fdad6b62f12   \n",
       "26  aa8433cd5f28980726dab95cccd6f010   \n",
       "27  cf99faad89b1684f8eb5db3968edf8ea   \n",
       "28  ec05efa5dc036fb8eba68ba33b0bbeed   \n",
       "29  95d6739648e1650640dfef2871a33798   \n",
       "30  b225d7f451b7da523bfb641c4fb5c3e4   \n",
       "31  35632daa0a9bd7f59515a1076a65d828   \n",
       "32  caaaa91a27dcec59149b94dc6553e0fc   \n",
       "33  1d1e71b8573647b72e3b14b5f118f5d5   \n",
       "34  11df44f1b07ecd92b6bf76c86161526c   \n",
       "35  f8b20a9e36543c3c5116c1975b1580d1   \n",
       "36  e743019b96626ebde90aad204e1a7401   \n",
       "37  2e467997bf247acf54d5ea84341cfa0f   \n",
       "38  fe5f061a600cb6775207ac3a43dd28d1   \n",
       "39  484931a9c4d643247cb8241366199734   \n",
       "40  cf523a4c0ccf2e84bb3dcaa5808a5bf4   \n",
       "41  085c76710186808e951cfc3bc5dfe2ba   \n",
       "42  dbcc48c3b0b98c77a5775b28195836bb   \n",
       "43  06b9c94b56af45a7941cc1acfee3201b   \n",
       "44  b17370777e8f949375c7fca369e7eea1   \n",
       "45  b25fb69841375fde97fee16b3582c8b3   \n",
       "46  8ebc2ddfd797cc1b0112634d3260489f   \n",
       "47  e98ff6ad02b97487df562cfd3854a378   \n",
       "48  3cf87293fa36531ac683b457770e8fb5   \n",
       "49  110836b5cd6a64ba8d508d1fb7c6630c   \n",
       "\n",
       "                                        preds_raw_int  \\\n",
       "0                 [2472, 330, 1489, 3, 3964, 5307, 1]   \n",
       "1                                        [5755, 7, 1]   \n",
       "2   [139, 3, 9, 96, 7, 210, 23, 635, 53, 5040, 121...   \n",
       "3          [3, 9, 2259, 13, 96, 14492, 12064, 121, 1]   \n",
       "4   [3, 9, 3, 122, 63, 19819, 4940, 6, 2576, 4672, 1]   \n",
       "5    [9699, 53, 6257, 24301, 120, 28, 3, 9, 18371, 1]   \n",
       "6                                          [12259, 1]   \n",
       "7   [3, 88, 1217, 112, 5022, 11, 2992, 8, 14961, 1...   \n",
       "8   [2347, 2448, 1215, 14528, 45, 5511, 9818, 227,...   \n",
       "9                    [7078, 8, 74, 969, 406, 6059, 1]   \n",
       "10                                   [1460, 17, 9, 1]   \n",
       "11                                [7507, 26, 9361, 1]   \n",
       "12                               [3, 15, 26, 2239, 1]   \n",
       "13             [8, 8581, 7, 123, 12417, 11, 29991, 1]   \n",
       "14                         [3, 5846, 1024, 15, 40, 1]   \n",
       "15  [5931, 5914, 19, 7966, 1427, 1381, 28, 8, 2669...   \n",
       "16                              [183, 1496, 23, 9, 1]   \n",
       "17                                   [42, 2613, 7, 1]   \n",
       "18                                         [20747, 1]   \n",
       "19                         [16, 112, 12996, 12268, 1]   \n",
       "20                        [8, 146, 1050, 36, 4862, 1]   \n",
       "21                                 [640, 3, 28188, 1]   \n",
       "22                       [6541, 1655, 6895, 15311, 1]   \n",
       "23                            [12, 1369, 160, 333, 1]   \n",
       "24                               [409, 109, 18956, 1]   \n",
       "25  [1527, 7637, 397, 97, 12, 14017, 15, 4761, 127...   \n",
       "26  [3, 88, 1217, 112, 5022, 11, 2992, 8, 14961, 1...   \n",
       "27                              [183, 1496, 23, 9, 1]   \n",
       "28  [12, 1709, 8, 11970, 45, 3507, 125, 19, 1187, ...   \n",
       "29  [12, 143, 12243, 257, 11, 12, 3990, 4921, 1452...   \n",
       "30                             [2576, 2565, 25857, 1]   \n",
       "31                         [3, 26, 3142, 21, 6216, 1]   \n",
       "32  [96, 122, 3623, 103, 1222, 120, 3, 35, 9, 3706...   \n",
       "33                   [6718, 15, 40, 36, 624, 1306, 1]   \n",
       "34                         [1614, 4518, 11, 10989, 1]   \n",
       "35  [7637, 397, 1911, 6626, 302, 1798, 1911, 7, 15...   \n",
       "36                                 [14566, 15, 26, 1]   \n",
       "37  [3, 99, 8, 146, 1050, 19, 4403, 12, 2222, 160,...   \n",
       "38  [3, 88, 2428, 66, 3, 287, 277, 12, 3, 9, 2259,...   \n",
       "39                               [3, 29, 15, 8172, 1]   \n",
       "40                          [9549, 3, 17801, 1018, 1]   \n",
       "41                       [6541, 1655, 6895, 15311, 1]   \n",
       "42  [3, 9, 568, 11970, 13, 3, 9, 5447, 19, 1940, 1...   \n",
       "43  [16, 3, 9, 1322, 3, 16718, 57, 3, 9, 4772, 18,...   \n",
       "44                      [7637, 397, 13102, 60, 17, 1]   \n",
       "45  [321, 3377, 33, 8672, 1345, 8592, 15, 26, 12, ...   \n",
       "46  [8, 146, 1050, 19, 646, 36, 60, 89, 17, 13, 32...   \n",
       "47                                          [9328, 1]   \n",
       "48                          [3819, 13, 5511, 9818, 1]   \n",
       "49                                           [872, 1]   \n",
       "\n",
       "                                        preds_raw_str  preds_raw_count  \\\n",
       "0                   [▁doctor, ▁pas, cal, ▁, rou, gon]                6   \n",
       "1                                       [▁convert, s]                2   \n",
       "2       [▁into, ▁, a, ▁\", s, w, i, mm, ing, ▁tank, \"]               11   \n",
       "3   [▁, a, ▁competition, ▁of, ▁\", court, ▁complime...                8   \n",
       "4             [▁, a, ▁, g, y, psy, ▁boy, ,, ▁pa, blo]               10   \n",
       "5   [▁wound, ing, ▁herself, ▁mortal, ly, ▁with, ▁,...                9   \n",
       "6                                          [▁suicide]                1   \n",
       "7   [▁, he, ▁takes, ▁his, ▁orders, ▁and, ▁becomes,...               12   \n",
       "8   [▁gets, ▁himself, ▁ex, pelled, ▁from, ▁cam, br...               12   \n",
       "9   [▁attending, ▁the, ▁der, by, ▁without, ▁permis...                6   \n",
       "10                                       [▁mal, t, a]                3   \n",
       "11                                   [▁nume, d, ides]                3   \n",
       "12                                    [▁, e, d, ward]                4   \n",
       "13          [▁the, ▁god, s, ▁cu, pid, ▁and, ▁mercury]                7   \n",
       "14                                 [▁, rap, ha, e, l]                5   \n",
       "15  [▁vi, vie, ▁is, ▁romantic, ally, ▁involved, ▁w...               12   \n",
       "16                                   [▁am, nes, i, a]                4   \n",
       "17                                     [▁or, este, s]                3   \n",
       "18                                            [▁echo]                1   \n",
       "19                   [▁in, ▁his, ▁isolated, ▁cottage]                4   \n",
       "20                    [▁the, ▁du, ke, ▁be, ▁informed]                5   \n",
       "21                               [▁across, ▁, europe]                3   \n",
       "22                           [▁scar, let, ▁cit, adel]                4   \n",
       "23                           [▁to, ▁win, ▁her, ▁love]                4   \n",
       "24                                    [▁va, le, rius]                3   \n",
       "25  [▁gives, ▁ser, ge, ▁time, ▁to, ▁contemplat, e,...               12   \n",
       "26  [▁, he, ▁takes, ▁his, ▁orders, ▁and, ▁becomes,...               12   \n",
       "27                                   [▁am, nes, i, a]                4   \n",
       "28  [▁to, ▁prevent, ▁the, ▁accused, ▁from, ▁hearin...               11   \n",
       "29  [▁to, ▁make, ▁repar, ation, ▁and, ▁to, ▁pur, i...               12   \n",
       "30                           [▁pa, gan, ▁philosopher]                3   \n",
       "31                            [▁, d, ick, ▁for, rest]                5   \n",
       "32  [▁\", g, row, ▁do, ting, ly, ▁, en, a, more, d,...               12   \n",
       "33                      [▁colon, e, l, ▁be, ver, ley]                6   \n",
       "34                      [▁court, iers, ▁and, ▁ladies]                4   \n",
       "35  [▁ser, ge, ▁mon, stro, us, ▁former, ▁mon, s, e...               11   \n",
       "36                                    [▁poison, e, d]                3   \n",
       "37  [▁, if, ▁the, ▁du, ke, ▁is, ▁willing, ▁to, ▁we...               12   \n",
       "38  [▁, he, ▁challenges, ▁all, ▁, com, ers, ▁to, ▁...               12   \n",
       "39                                   [▁, n, e, media]                4   \n",
       "40                             [▁mount, ▁, heli, con]                4   \n",
       "41                           [▁scar, let, ▁cit, adel]                4   \n",
       "42  [▁, a, ▁person, ▁accused, ▁of, ▁, a, ▁crime, ▁...               12   \n",
       "43  [▁in, ▁, a, ▁land, ▁, ruled, ▁by, ▁, a, ▁semi,...               12   \n",
       "44                            [▁ser, ge, ▁mou, re, t]                5   \n",
       "45  [▁both, ▁doors, ▁are, ▁heavily, ▁sound, proof,...               12   \n",
       "46  [▁the, ▁du, ke, ▁is, ▁left, ▁be, re, f, t, ▁of...               12   \n",
       "47                                       [▁execution]                1   \n",
       "48                   [▁university, ▁of, ▁cam, bridge]                4   \n",
       "49                                           [▁white]                1   \n",
       "\n",
       "    truncated  score_proba                                   preds_raw_scores  \n",
       "0           1     0.444278  [0.45619308948516846, 0.9993246793746948, 0.99...  \n",
       "1           1     0.685860  [0.8886101841926575, 0.9971410036087036, 0.774...  \n",
       "2           1     0.549538  [0.7651849389076233, 0.9803006052970886, 0.999...  \n",
       "3           1     0.397013  [0.45407775044441223, 0.9586190581321716, 0.97...  \n",
       "4           1     0.159552  [0.6082004308700562, 0.5329281687736511, 0.945...  \n",
       "5           1     0.128462  [0.1338125765323639, 0.986093282699585, 0.9979...  \n",
       "6           1     0.231917           [0.2435421347618103, 0.9522663950920105]  \n",
       "7           1     0.031928  [0.1293245106935501, 0.5078274011611938, 0.674...  \n",
       "8           1     0.580548  [0.671929121017456, 0.996823787689209, 0.99861...  \n",
       "9           1     0.144703  [0.19296632707118988, 0.9960280656814575, 0.99...  \n",
       "10          1     0.644998  [0.6620191931724548, 0.9785651564598083, 0.999...  \n",
       "11          1     0.995102  [0.9992285966873169, 0.999927282333374, 0.9999...  \n",
       "12          1     0.970942  [0.988783061504364, 0.9949404001235962, 0.9999...  \n",
       "13          1     0.199961  [0.5570692420005798, 0.7717386484146118, 0.999...  \n",
       "14          1     0.817120  [0.8455095291137695, 0.9790767431259155, 0.999...  \n",
       "15          1     0.206347  [0.4402723014354706, 0.9986995458602905, 0.492...  \n",
       "16          1     0.507416  [0.7028640508651733, 0.999924898147583, 0.9994...  \n",
       "17          1     0.873690  [0.8847248554229736, 0.9998818635940552, 0.993...  \n",
       "18          1     0.872898           [0.8892452716827393, 0.9816162586212158]  \n",
       "19          1     0.272569  [0.29214540123939514, 0.9823294281959534, 0.99...  \n",
       "20          1     0.244704  [0.43049895763397217, 0.8131089806556702, 0.99...  \n",
       "21          1     0.939584  [0.9418609142303467, 0.9989416003227234, 0.999...  \n",
       "22          1     0.499267  [0.5013013482093811, 0.9998759031295776, 0.999...  \n",
       "23          1     0.845291  [0.8542860150337219, 0.9976438879966736, 0.999...  \n",
       "24          1     0.956286  [0.9584904909133911, 0.9999479055404663, 0.999...  \n",
       "25          1     0.135798  [0.22910034656524658, 0.7027128338813782, 0.99...  \n",
       "26          1     0.035583  [0.19860149919986725, 0.6356847286224365, 0.42...  \n",
       "27          1     0.524897  [0.9556050300598145, 0.9999589920043945, 0.999...  \n",
       "28          1     0.222488  [0.29350370168685913, 0.9497087001800537, 0.92...  \n",
       "29          1     0.375621  [0.5159768462181091, 0.9927565455436707, 0.999...  \n",
       "30          1     0.469371  [0.47555890679359436, 0.9999902248382568, 0.98...  \n",
       "31          1     0.565650  [0.5787684917449951, 0.9824212193489075, 0.999...  \n",
       "32          1     0.863766  [0.8664252758026123, 0.9995844960212708, 0.999...  \n",
       "33          1     0.812355  [0.8338054418563843, 0.9998393058776855, 0.999...  \n",
       "34          1     0.369390  [0.43628817796707153, 0.9973414540290833, 0.97...  \n",
       "35          1     0.129434  [0.5341707468032837, 0.8531247973442078, 0.338...  \n",
       "36          1     0.292247  [0.3425084054470062, 0.9881272912025452, 0.999...  \n",
       "37          1     0.244028  [0.6225618124008179, 0.425942987203598, 0.9718...  \n",
       "38          1     0.281100  [0.309281587600708, 0.9353982210159302, 0.9929...  \n",
       "39          1     0.552084  [0.8192062973976135, 0.995919942855835, 0.9999...  \n",
       "40          1     0.914243  [0.9163744449615479, 0.9995006322860718, 0.999...  \n",
       "41          1     0.219856  [0.22041581571102142, 0.9998772144317627, 0.99...  \n",
       "42          1     0.109603  [0.3296971619129181, 0.5810139775276184, 0.581...  \n",
       "43          1     0.341133  [0.3780934810638428, 0.9662409424781799, 0.999...  \n",
       "44          1     0.977961  [0.9852861166000366, 0.9996968507766724, 0.997...  \n",
       "45          1     0.135646  [0.24964524805545807, 0.9974580407142639, 0.99...  \n",
       "46          1     0.169563  [0.3738134205341339, 0.48040515184402466, 0.99...  \n",
       "47          1     0.319445            [0.3407576084136963, 0.937455952167511]  \n",
       "48          1     0.546961  [0.5519163012504578, 0.9973983764648438, 0.999...  \n",
       "49          1     0.650060           [0.9553894400596619, 0.6804133653640747]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import filterfalse \n",
    "from utils_generic import generate_uuid\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GreedyGenerator:\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._num_beams = 1\n",
    "        self._do_sample = False\n",
    "        self._clean_up_tokenization_spaces = True\n",
    "        self._skip_special_tokens = True\n",
    "        \n",
    "    @property\n",
    "    def generate_hyperparams(self) -> dict:\n",
    "        return {\n",
    "            'num_beams': self._num_beams,\n",
    "            'do_sample': self._do_sample,\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def decoding_hyperparams(self) -> dict:\n",
    "        return {\n",
    "            \"clean_up_tokenization_spaces\": self._clean_up_tokenization_spaces,\n",
    "            \"skip_special_tokens\": self._skip_special_tokens,\n",
    "        }\n",
    "    \n",
    "    def generate(self, data, id_cols, tokenizer, model, batch_size: int=None, **kwargs) -> dict:\n",
    "        \"\"\"\n",
    "            - `score_proba`: score associated with the generated sentence. computed as the multiplication of the individual raw_scores. the score is within $[0, 1]$.\n",
    "            - `preds`: textual representation of the generated instance\n",
    "            - `preds_raw_int`: tokens id \n",
    "            - `preds_raw_str`: tokens str\n",
    "            - `preds_raw_scores`: scores for each of the tokens, lie in the range $[0, 1]$.\n",
    "            - `len`: length of the sentence\n",
    "            - `truncated`: whether the sequence was truncated (i.e., actually had the eos token).\n",
    "        \"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = len(data)\n",
    "        else:\n",
    "            batch_size = min(batch_size, len(data))\n",
    "        \n",
    "        n = len(data)\n",
    "        logging.info(f\"Processing {n} examples in total\")\n",
    "        for b_start in range(0, n, batch_size):\n",
    "            metadata = { }\n",
    "            # Batch indexing\n",
    "            # ---------------------------------------------------------------\n",
    "            b_end = b_start + batch_size\n",
    "            b_end = min(b_end, n) \n",
    "            batch = data.select(range(b_start, b_end))\n",
    "            logging.info(f\"Processing examples {b_start}-{b_end}\")\n",
    "            \n",
    "            metadata.update({id_col: batch[id_col] for id_col in id_cols})\n",
    "            \n",
    "            # Generate\n",
    "            # ---------------------------------------------------------------\n",
    "            results = model.generate(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                # We're interested in returning information about the scores\n",
    "                output_scores=True,\n",
    "                return_dict_in_generate=True,\n",
    "                # Force truncation (ensure the last token is always the EOS)\n",
    "                forced_eos_token_id=tokenizer.eos_token_id,\n",
    "                **self.generate_hyperparams,            \n",
    "                **kwargs, # max_length\n",
    "            )\n",
    "\n",
    "            # Textual representation of the predicted sequence\n",
    "            metadata[\"preds\"] = tokenizer.batch_decode(results.sequences, **self.decoding_hyperparams)\n",
    "\n",
    "            # Compute unique identifiers for each prediction\n",
    "            # Ideally the identifier will depend on the model's,\n",
    "            # the tokenizer's and the matrix's uuid but for now\n",
    "            # we will simplify and only consider the generated text.\n",
    "            #\n",
    "            # Note: This assumes the name of the prediction file is being\n",
    "            # handled by some component that has access to all this information\n",
    "            # and is, therefore, able to avoid name clashes.\n",
    "            uuid_metadata = { }\n",
    "            uuid = lambda pred: generate_uuid(dict(text=pred, **uuid_metadata))\n",
    "            metadata[\"preds_id\"] = [uuid(pred) for pred in metadata[\"preds\"]]\n",
    "            \n",
    "            # Individual tokens raw representation\n",
    "            def skip_tokens(seq, token):\n",
    "                predicate = filterfalse(lambda t: t == token, seq)\n",
    "                return list(predicate)\n",
    "            \n",
    "            metadata[\"preds_raw_int\"] = results.sequences.tolist()\n",
    "            metadata[\"preds_raw_int\"] = [skip_tokens(s, tokenizer.pad_token_id)\n",
    "                                         for s in metadata[\"preds_raw_int\"]]\n",
    "            \n",
    "            # Individual tokens raw textual representation\n",
    "            #metadata[\"preds_raw_str\"] = [[tokenizer.decode(t, skip_special_tokens=True) for t in seq]\n",
    "            metadata[\"preds_raw_str\"] = [tokenizer.convert_ids_to_tokens(seq, skip_special_tokens=True)\n",
    "                                        for seq in metadata[\"preds_raw_int\"]]\n",
    "\n",
    "            # Individual tokens count (does not include special tokens like EOS or pad)\n",
    "            metadata[\"preds_raw_count\"] = list(map(len, metadata[\"preds_raw_str\"]))\n",
    "\n",
    "            # Whether the sentence was truncated or not (i.e., it has an EOS token)\n",
    "            is_truncated = lambda s: int(any(s == tokenizer.eos_token_id))\n",
    "            metadata[\"truncated\"] = [is_truncated(seq) for seq in results.sequences] \n",
    "\n",
    "            # ---------------------------------------------------------------------------------\n",
    "            # Compute score_proba\n",
    "            # ---------------------------------------------------------------------------------\n",
    "            # Pair each timestep logits `score_t` with corresponding generated token\n",
    "            # *Note*: since greedy_results.scores is a T sized tuple with B * V matrices\n",
    "            # representing the logits for the different instances in the batch at each timestep\n",
    "            # we can couple the actual logit score at each timestep with the corresponding token.\n",
    "            scores, seq_tokens = results.scores, results.sequences[:,1:]\n",
    "            # ^Note: The sequences are considering an initial pad token whose score is not outputted\n",
    "            # by the greedy decoder.\n",
    "            assert len(scores) == seq_tokens.shape[-1], \"Dimension mismatch: Sequences vs scores\"\n",
    "\n",
    "            n_pred_timesteps = len(scores)\n",
    "            scores_tokens = [(F.log_softmax(scores[t], dim=-1), seq_tokens[:,t]) for t in range(n_pred_timesteps)]\n",
    "            #^Note: \n",
    "            # - `scores` is a |B| X |V| matrix with all the logits per batch per vocabulary\n",
    "            # at prediction timestep t. Like Jiang et. al \n",
    "            # (https://github.com/jzbjyb/lm-calibration/blob/887e3e13df0462842ce288fffe588e549a3360ee/model/gpt2.py#L67)\n",
    "            # we apply F.log_softmax to ensure the logprobabilities are comparable amongst\n",
    "            # the different batches\n",
    "            # - `seq_tokens[:, t]` is a |B| X 1 matrix with the predicted token types at\n",
    "            # timestep t\n",
    "            greedy_scores = [scores_t.gather(-1, token_t.unsqueeze(-1)) for scores_t, token_t in scores_tokens]\n",
    "            greedy_scores = torch.cat(greedy_scores, dim=1)\n",
    "            # Must mask the greedy scores corresponding to the padding\n",
    "            pad_mask = (seq_tokens == tokenizer.pad_token_id)\n",
    "            greedy_scores[pad_mask] = 0\n",
    "\n",
    "            metadata[\"score_proba\"] = torch.exp(torch.sum(greedy_scores, dim=1)).tolist()\n",
    "            metadata[\"preds_raw_scores\"] = torch.exp(greedy_scores).tolist()\n",
    "            \n",
    "            # Drop the tokens that are not important\n",
    "            metadata[\"preds_raw_scores\"] = [skip_tokens(s, 1) for s in metadata[\"preds_raw_scores\"]]\n",
    "            yield pd.DataFrame(metadata)\n",
    "            \n",
    "            \n",
    "# Sanity check (:\n",
    "batches = iter(GreedyGenerator().generate(\n",
    "    batch, id_cols=ID_COLS, model=model._model, tokenizer=model._tokenizer, max_length=14, batch_size=50))\n",
    "b = next(batches)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6e155c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import importlib\n",
    "\n",
    "\n",
    "def import_method(fullpath: str) -> Callable:\n",
    "    \"\"\"Import a specific method given the corresponding path.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fullpath: str\n",
    "        Path of method to import.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    method: callable\n",
    "        The method object.\n",
    "    \"\"\"\n",
    "    if fullpath is None:\n",
    "        raise ValueError(f\"Cannot import method {fullpath}\")\n",
    "    \n",
    "    paths = fullpath.rsplit('.', 1)\n",
    "    \n",
    "    if len(paths) == 1:\n",
    "        module, method = \"__main__\", paths\n",
    "    else:\n",
    "        module, method = paths\n",
    "    \n",
    "    try:\n",
    "        module = importlib.import_module(module)\n",
    "    except:\n",
    "        module = import_method(module)\n",
    "    return getattr(module, method)\n",
    "\n",
    "\n",
    "def method_name(method: Callable) -> str:\n",
    "    module = method.__module__\n",
    "    qualname = method.__qualname__\n",
    "    \n",
    "    return f\"{module}.{qualname}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d119ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Union, Iterable\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OutputResult:\n",
    "    filename: str\n",
    "        \n",
    "    output_fn_classpath: str = field(default=\"pandas.DataFrame.to_csv\")\n",
    "    output_fn_kwargs: dict = field(default_factory=dict)\n",
    "    output_dir: str = field(default=\"./outputs\")\n",
    "    out_extension: str = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_fn_kwargs = {\n",
    "            \"compression\": \"gzip\",\n",
    "            \"index\": False,\n",
    "            \"header\": True,\n",
    "            \"encoding\": \"utf-8\",\n",
    "        }        \n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "        # Dynamically load function\n",
    "        if isinstance(self.output_fn_classpath, str):\n",
    "            self.output_fn = import_method(self.output_fn_classpath)\n",
    "    \n",
    "        elif isinstance(self.output_fn_classpath, callable):\n",
    "            self.output_fn = self.output_fn_classpath\n",
    "            self.output_fn_classpath = method_name(self.output_fn_classpath)\n",
    "\n",
    "    @property\n",
    "    def filepath(self):\n",
    "        filepath = f\"{self.output_dir}/{self.filename}\"\n",
    "        if self.out_extension:\n",
    "            filepath = f\"{filepath}.{out_extension}\"\n",
    "        return filepath\n",
    "    \n",
    "    @property\n",
    "    def configpath(self):\n",
    "        return f\"{self.filepath}.out_config\"\n",
    "        \n",
    "    def dump_configs(self):\n",
    "        with open(self.configpath , \"w\") as f:\n",
    "            yaml.dump(self.output_fn_kwargs, f)\n",
    "            \n",
    "    def write(self, batches: Iterable, exists_new: bool=True):\n",
    "        batches = iter(batches)\n",
    "        \n",
    "        out_kwargs = self.output_fn_kwargs.copy()\n",
    "        \n",
    "        if exists_new is True:\n",
    "            first_batch = next(batches)\n",
    "            out_kwargs[\"mode\"] = \"w\"\n",
    "            logging.info(f\"Creating file {self.filepath} w/ {self.output_fn_classpath} and arguments: {out_kwargs}\")\n",
    "            self.output_fn(first_batch, self.filepath, **out_kwargs)\n",
    "            out_kwargs[\"header\"] = False\n",
    "\n",
    "        out_kwargs[\"mode\"] = \"a\"\n",
    "        for batch in batches:\n",
    "            self.output_fn(batch, self.filepath, **out_kwargs)\n",
    "        \n",
    "        self.dump_configs()\n",
    "        \n",
    "\n",
    "# Sanity check (:\n",
    "OutputResult(\"test.txt\").write(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e12cf928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_id</th>\n",
       "      <th>preds_raw_int</th>\n",
       "      <th>preds_raw_str</th>\n",
       "      <th>preds_raw_count</th>\n",
       "      <th>truncated</th>\n",
       "      <th>score_proba</th>\n",
       "      <th>preds_raw_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e4470b4cf3b0e1ac33a7df420f3330c5</td>\n",
       "      <td>92efeb81c61ddc7329ff790463e7b571</td>\n",
       "      <td>pre-hyborian empire of acher</td>\n",
       "      <td>2b6e48fa493821a89e8f8890c31ad02e</td>\n",
       "      <td>[554, 18, 107, 63, 115, 32, 5288, 21039, 13, 3...</td>\n",
       "      <td>['▁pre', '-', 'h', 'y', 'b', 'o', 'rian', '▁em...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>[0.587063729763031, 0.9998001456260681, 0.9990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3ec8bc0b55fd924732cb1ee6a2be87c7</td>\n",
       "      <td>9d686cf84b96ded14795fe2c10fd7a5b</td>\n",
       "      <td>frank strawn-hamilton</td>\n",
       "      <td>a0bc0382c1322576cb76af418746b042</td>\n",
       "      <td>[3, 89, 6254, 21920, 29, 18, 1483, 23, 7377, 1]</td>\n",
       "      <td>['▁', 'f', 'rank', '▁straw', 'n', '-', 'ham', ...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.385791</td>\n",
       "      <td>[0.550155520439148, 0.706671953201294, 0.99998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b85207cc18922156da06749514ae7ae4</td>\n",
       "      <td>4ef87189b2550c086d08819c7b85ebdd</td>\n",
       "      <td>abbot of his monastery</td>\n",
       "      <td>592a416c6bbfc98f207f566a66d00a04</td>\n",
       "      <td>[703, 4045, 13, 112, 29592, 1]</td>\n",
       "      <td>['▁ab', 'bot', '▁of', '▁his', '▁monastery']</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.612940</td>\n",
       "      <td>[0.9626514315605164, 0.9999915361404419, 0.647...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2260ae74efff1f474eeb0ea2ab38f89e</td>\n",
       "      <td>dffb85d46b8a8030635734a62624eb5a</td>\n",
       "      <td>make zenobia his queen</td>\n",
       "      <td>5eb23cf32e10d12e1098d6cd95a98d51</td>\n",
       "      <td>[143, 3, 1847, 6690, 9, 112, 14915, 1]</td>\n",
       "      <td>['▁make', '▁', 'zen', 'obi', 'a', '▁his', '▁qu...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179402</td>\n",
       "      <td>[0.18902887403964996, 0.9879463315010071, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fcc79b6e8bb0c6221e81cc489a5eaaf8</td>\n",
       "      <td>70d027b8da1225649c15c951b7f2929d</td>\n",
       "      <td>serge is portrayed giving several wildly enthu...</td>\n",
       "      <td>20f038e8e8c3b331c02451d9e0375d80</td>\n",
       "      <td>[7637, 397, 19, 3, 27486, 1517, 633, 3, 28890,...</td>\n",
       "      <td>['▁ser', 'ge', '▁is', '▁', 'portrayed', '▁givi...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035970</td>\n",
       "      <td>[0.1573231816291809, 0.9991739392280579, 0.262...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>cb25a066e09c116f9519a5a77e9a0b5f</td>\n",
       "      <td>b0b95faf20f3d7991d8bb09a1e08a4ae</td>\n",
       "      <td>patience</td>\n",
       "      <td>3b5bfb437430411c9990d029972d497b</td>\n",
       "      <td>[11998, 1]</td>\n",
       "      <td>['▁patience']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.784210</td>\n",
       "      <td>[0.8764203190803528, 0.8947872519493103]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>92cf35db62a8b8b885ae6bd88b74796e</td>\n",
       "      <td>83eeb53928af196b2521ec80c13d3594</td>\n",
       "      <td>alexandria</td>\n",
       "      <td>ddc42a3937dc82ea8f2a094e82c6b1eb</td>\n",
       "      <td>[1240, 226, 232, 52, 23, 9, 1]</td>\n",
       "      <td>['▁ale', 'x', 'and', 'r', 'i', 'a']</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.911054</td>\n",
       "      <td>[0.9166275858879089, 0.999991774559021, 0.9999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>3215cbad5038466d27701023ed9b1425</td>\n",
       "      <td>b07f2a24dd9d08626ce39fbc31afa97c</td>\n",
       "      <td>lady mabel grex</td>\n",
       "      <td>c95fd0ced49c47fe215d16c97d51d870</td>\n",
       "      <td>[9360, 954, 2370, 3542, 994, 1]</td>\n",
       "      <td>['▁lady', '▁ma', 'bel', '▁gr', 'ex']</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.593906</td>\n",
       "      <td>[0.8748897314071655, 0.6942394375801086, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>69fb15c137edf9c225875ffa7112906a</td>\n",
       "      <td>e23c2e8728e615c361a843ec13823480</td>\n",
       "      <td>frank tregear</td>\n",
       "      <td>4e5be9eac0b8795072ddc8f213d9a44e</td>\n",
       "      <td>[3, 89, 6254, 3, 929, 397, 291, 1]</td>\n",
       "      <td>['▁', 'f', 'rank', '▁', 'tre', 'ge', 'ar']</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137433</td>\n",
       "      <td>[0.20879089832305908, 0.6718905568122864, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>67097f32f76f45666a6f5371a5aae5f1</td>\n",
       "      <td>11f5bdf3930169e5a69235baadcd872d</td>\n",
       "      <td>philammon</td>\n",
       "      <td>8e2025ffac54e31e7ca4f8cd143d8272</td>\n",
       "      <td>[3, 18118, 265, 2157, 1]</td>\n",
       "      <td>['▁', 'phil', 'am', 'mon']</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885049</td>\n",
       "      <td>[0.9063523411750793, 0.9851705431938171, 0.999...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           example_id                         answer_id  \\\n",
       "0    e4470b4cf3b0e1ac33a7df420f3330c5  92efeb81c61ddc7329ff790463e7b571   \n",
       "1    3ec8bc0b55fd924732cb1ee6a2be87c7  9d686cf84b96ded14795fe2c10fd7a5b   \n",
       "2    b85207cc18922156da06749514ae7ae4  4ef87189b2550c086d08819c7b85ebdd   \n",
       "3    2260ae74efff1f474eeb0ea2ab38f89e  dffb85d46b8a8030635734a62624eb5a   \n",
       "4    fcc79b6e8bb0c6221e81cc489a5eaaf8  70d027b8da1225649c15c951b7f2929d   \n",
       "..                                ...                               ...   \n",
       "222  cb25a066e09c116f9519a5a77e9a0b5f  b0b95faf20f3d7991d8bb09a1e08a4ae   \n",
       "223  92cf35db62a8b8b885ae6bd88b74796e  83eeb53928af196b2521ec80c13d3594   \n",
       "224  3215cbad5038466d27701023ed9b1425  b07f2a24dd9d08626ce39fbc31afa97c   \n",
       "225  69fb15c137edf9c225875ffa7112906a  e23c2e8728e615c361a843ec13823480   \n",
       "226  67097f32f76f45666a6f5371a5aae5f1  11f5bdf3930169e5a69235baadcd872d   \n",
       "\n",
       "                                                 preds  \\\n",
       "0                         pre-hyborian empire of acher   \n",
       "1                                frank strawn-hamilton   \n",
       "2                               abbot of his monastery   \n",
       "3                               make zenobia his queen   \n",
       "4    serge is portrayed giving several wildly enthu...   \n",
       "..                                                 ...   \n",
       "222                                           patience   \n",
       "223                                         alexandria   \n",
       "224                                    lady mabel grex   \n",
       "225                                      frank tregear   \n",
       "226                                          philammon   \n",
       "\n",
       "                             preds_id  \\\n",
       "0    2b6e48fa493821a89e8f8890c31ad02e   \n",
       "1    a0bc0382c1322576cb76af418746b042   \n",
       "2    592a416c6bbfc98f207f566a66d00a04   \n",
       "3    5eb23cf32e10d12e1098d6cd95a98d51   \n",
       "4    20f038e8e8c3b331c02451d9e0375d80   \n",
       "..                                ...   \n",
       "222  3b5bfb437430411c9990d029972d497b   \n",
       "223  ddc42a3937dc82ea8f2a094e82c6b1eb   \n",
       "224  c95fd0ced49c47fe215d16c97d51d870   \n",
       "225  4e5be9eac0b8795072ddc8f213d9a44e   \n",
       "226  8e2025ffac54e31e7ca4f8cd143d8272   \n",
       "\n",
       "                                         preds_raw_int  \\\n",
       "0    [554, 18, 107, 63, 115, 32, 5288, 21039, 13, 3...   \n",
       "1      [3, 89, 6254, 21920, 29, 18, 1483, 23, 7377, 1]   \n",
       "2                       [703, 4045, 13, 112, 29592, 1]   \n",
       "3               [143, 3, 1847, 6690, 9, 112, 14915, 1]   \n",
       "4    [7637, 397, 19, 3, 27486, 1517, 633, 3, 28890,...   \n",
       "..                                                 ...   \n",
       "222                                         [11998, 1]   \n",
       "223                     [1240, 226, 232, 52, 23, 9, 1]   \n",
       "224                    [9360, 954, 2370, 3542, 994, 1]   \n",
       "225                 [3, 89, 6254, 3, 929, 397, 291, 1]   \n",
       "226                           [3, 18118, 265, 2157, 1]   \n",
       "\n",
       "                                         preds_raw_str  preds_raw_count  \\\n",
       "0    ['▁pre', '-', 'h', 'y', 'b', 'o', 'rian', '▁em...               12   \n",
       "1    ['▁', 'f', 'rank', '▁straw', 'n', '-', 'ham', ...                9   \n",
       "2          ['▁ab', 'bot', '▁of', '▁his', '▁monastery']                5   \n",
       "3    ['▁make', '▁', 'zen', 'obi', 'a', '▁his', '▁qu...                7   \n",
       "4    ['▁ser', 'ge', '▁is', '▁', 'portrayed', '▁givi...               12   \n",
       "..                                                 ...              ...   \n",
       "222                                      ['▁patience']                1   \n",
       "223                ['▁ale', 'x', 'and', 'r', 'i', 'a']                6   \n",
       "224               ['▁lady', '▁ma', 'bel', '▁gr', 'ex']                5   \n",
       "225         ['▁', 'f', 'rank', '▁', 'tre', 'ge', 'ar']                7   \n",
       "226                         ['▁', 'phil', 'am', 'mon']                4   \n",
       "\n",
       "     truncated  score_proba                                   preds_raw_scores  \n",
       "0            1     0.539075  [0.587063729763031, 0.9998001456260681, 0.9990...  \n",
       "1            1     0.385791  [0.550155520439148, 0.706671953201294, 0.99998...  \n",
       "2            1     0.612940  [0.9626514315605164, 0.9999915361404419, 0.647...  \n",
       "3            1     0.179402  [0.18902887403964996, 0.9879463315010071, 0.99...  \n",
       "4            1     0.035970  [0.1573231816291809, 0.9991739392280579, 0.262...  \n",
       "..         ...          ...                                                ...  \n",
       "222          1     0.784210           [0.8764203190803528, 0.8947872519493103]  \n",
       "223          1     0.911054  [0.9166275858879089, 0.999991774559021, 0.9999...  \n",
       "224          1     0.593906  [0.8748897314071655, 0.6942394375801086, 0.999...  \n",
       "225          1     0.137433  [0.20879089832305908, 0.6718905568122864, 0.99...  \n",
       "226          1     0.885049  [0.9063523411750793, 0.9851705431938171, 0.999...  \n",
       "\n",
       "[227 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./outputs/test.txt\", compression=\"gzip\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5754e014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
