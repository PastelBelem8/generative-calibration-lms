{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142a84d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kat/miniconda3/envs/gqa-env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.json\t    minimal_pairs.json.sha1   train.json\r\n",
      "dev.json.sha1\t    test_no_labels.json       train.json.sha1\r\n",
      "minimal_pairs.json  test_no_labels.json.sha1\r\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import datasets\n",
    "import pyarrow.lib as pylib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "MOCHA_DIR_PATH = \"../../datasets/mocha\"\n",
    "!ls {MOCHA_DIR_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b882d929",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "\n",
    "{\n",
    "    'candidate': 'I want to help Luke feed.',\n",
    "    'context': \"There is one area I want to work on . Breast - feeding . Right now , Luke's addicted to the bottle . We were so eager to wean him off his nose tube that when he started taking a bottle , we made it our only goal to re - enforce that .\",\n",
    "    'metadata': {\n",
    "        'scores': [1, 1, 1],\n",
    "        'source': 'gpt2',\n",
    "    },\n",
    "    'question': 'What may be your reason for wanting to work on Breast - feeding ?',\n",
    "    'reference': 'It could help my son .',\n",
    "    'score': 1,\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49fd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from collections import defaultdict\n",
    "from statistics import mean\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['tagger', 'parser', 'ner'])\n",
    "\n",
    "\n",
    "### Count statistics\n",
    "def num_passages(data: dict) -> int:\n",
    "    \"\"\"Count distinct passages in the provided ``data``.\n",
    "    \n",
    "    \n",
    "    We expect ``data`` to be organized as follows:\n",
    "    data = {\n",
    "        'uuid1': {\n",
    "            'candidate': \"He's a child and it's a very rare thing.\",\n",
    "            'context': 'Somewhere in me I knew it all along , there are all those moments when he stares into my eyes and his start to sparkle while this gorgeous grin spreads across his face . When he first started to do it I would ask him \" what ? What s funny ? \" he would always say nothing and attempt to divert his attention elsewhere .',\n",
    "            'metadata': {'scores': [1], 'source': 'gpt2'},\n",
    "            'question': \"What's a possible reason the guy stares into the writer's eyes ?\",\n",
    "            'reference': 'Because he likes her a lot .',\n",
    "            'score': 1,\n",
    "        },\n",
    "        ...,\n",
    "        'uuidn': {\n",
    "            'candidate': 'The kitten would have been killed.',\n",
    "            'context': 'Her dog and another kitten kept trying to escape the house while all this was going on . It was awkward and sad . I tried to be comforting because I could tell she was truly distraught but I was honestly mad at her for letting her animals out in the first place . She told me that she gave three of the kittens away to a home with dogs and two of them had been killed by the dogs already .',\n",
    "            'metadata': {'scores': [1], 'source': 'gpt2'},\n",
    "            'question': \"What might be different if the friend didn't give away kittens to homes with dogs ?\",\n",
    "            'reference': \"Two of the kittens wouldn't have been killed\",\n",
    "            'score': 1,\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    seen_passages = set()\n",
    "    num = 0\n",
    "\n",
    "    for instance in data.values():\n",
    "        if instance['context'] not in seen_passages:\n",
    "            num += 1\n",
    "            seen_passages.add(instance['context'])\n",
    "\n",
    "    return num\n",
    "\n",
    "\n",
    "def num_ques_ref_pairs(data: dict) -> int:\n",
    "    \"\"\"Count distinct <context, question, ref> pairs in the provided ``data``.\n",
    "    \n",
    "    We expect data to be organized as indicated in ``num_passages``.\n",
    "    \"\"\"\n",
    "    seen_ques_ref_pairs = set()\n",
    "    num = 0\n",
    "\n",
    "    for instance in data.values():\n",
    "        ques_ref = instance['context'] + instance['question'] + instance['reference']\n",
    "        if ques_ref not in seen_ques_ref_pairs:\n",
    "            num += 1\n",
    "            seen_ques_ref_pairs.add(ques_ref)\n",
    "\n",
    "    return num\n",
    "\n",
    "\n",
    "def num_instances(data) -> int:\n",
    "    \"\"\"Count the number of examples in the data.\"\"\"\n",
    "    return len(data)\n",
    "\n",
    "\n",
    "def pct_ref_context_overlap(data) -> int:\n",
    "    counts = [1 if instance[\"reference\"] in instance[\"context\"] else 0 for instance in data.values()]\n",
    "    return round(mean(counts), 1)\n",
    "\n",
    "def pct_ref_question_overlap(data) -> int:\n",
    "    counts = [1 if instance[\"reference\"] in instance[\"question\"] else 0 for instance in data.values()]\n",
    "    return round(mean(counts), 1)\n",
    "\n",
    "    \n",
    "### Average length statistics\n",
    "def avg_passage_len(data) -> float:\n",
    "    \"\"\"Computer avg number of words in the context (includes punctuation)\"\"\"\n",
    "\n",
    "    lengths = [len(nlp(instance['context'])) for instance in data.values()]\n",
    "    return round(mean(lengths), 1)\n",
    "\n",
    "\n",
    "def avg_question_len(data) -> float:\n",
    "    \"\"\"Computer avg number of words in the question (includes punctuation)\"\"\"\n",
    "    lengths = [len(nlp(instance['question'])) for instance in data.values()]\n",
    "    return round(mean(lengths), 1)\n",
    "\n",
    "\n",
    "def avg_reference_len(data) -> float:\n",
    "    \"\"\"Computer avg number of words in the reference (includes punctuation)\"\"\"\n",
    "    lengths = [len(nlp(instance['reference'])) for instance in data.values()]\n",
    "    return round(mean(lengths), 1)\n",
    "\n",
    "\n",
    "def avg_candidate_len(data) -> float:\n",
    "    \"\"\"Computer avg number of words in the candidate (includes punctuation)\"\"\"\n",
    "    lengths = [len(nlp(instance['candidate'])) for instance in data.values()]\n",
    "    return round(mean(lengths), 1)\n",
    "\n",
    "\n",
    "def avg_candidate_agreement(data) -> float:\n",
    "    \"\"\"Compute the avg agreement in the candidate.\"\"\"\n",
    "    scores = [mean(instance['metadata'][\"scores\"]) for instance in data.values()]\n",
    "    return round(mean(scores), 1)\n",
    "\n",
    "    \n",
    "def avg_candidate_score(data) -> float:\n",
    "    \"\"\"Computer avg score candidate (includes punctuation)\"\"\"\n",
    "    scores = [instance['score'] for instance in data.values()]\n",
    "    return round(mean(scores), 1)\n",
    "\n",
    "def avg_num_annots_ques_ref(data: dict) -> int:\n",
    "    \"\"\"Compute avg number of annotations per <context, question, ref> pair\n",
    "    in the provided ``data``.\n",
    "    \n",
    "    We expect data to be organized as indicated in ``num_passages``.\n",
    "    \"\"\"\n",
    "    seen_ques_ref_pairs = {}\n",
    "\n",
    "    for instance in data.values():\n",
    "        ques_ref = instance['context'] + instance['question'] + instance['reference']\n",
    "        if ques_ref not in seen_ques_ref_pairs:\n",
    "            seen_ques_ref_pairs[ques_ref] = 1\n",
    "        else:\n",
    "            seen_ques_ref_pairs[ques_ref] += 1\n",
    "\n",
    "    seen_ques_ref_pairs = list(seen_ques_ref_pairs.values())\n",
    "    return round(mean(seen_ques_ref_pairs), 1)\n",
    "\n",
    "\n",
    "def get_statistics_for_split(file_path, compute_average_lengths=False, agreement_score=None):\n",
    "    data = json.load(open(file_path))\n",
    "    statistics = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    # Compute statistics per constituent dataset\n",
    "    for dataset in tqdm(data):\n",
    "        data_data = data[dataset]\n",
    "        # Filter if agreement score\n",
    "        if agreement_score:\n",
    "            data_data = {k: v for k, v in data_data.items() if v[\"score\"] >= agreement_score}\n",
    "  \n",
    "        \n",
    "        # Compute count statistics\n",
    "        statistics[dataset]['num_passages'] = num_passages(data_data)\n",
    "        statistics[dataset]['num_ques_ref_pairs'] = num_ques_ref_pairs(data_data)\n",
    "        statistics[dataset]['num_instances'] = num_instances(data_data)\n",
    "\n",
    "        # Average num_annots\n",
    "        statistics[dataset]['avg_annots_per_ques_ref_pair'] = avg_num_annots_ques_ref(data_data)\n",
    "        statistics[dataset]['pct_ref_cont_overlap'] = pct_ref_context_overlap(data_data)\n",
    "        statistics[dataset]['pct_ref_ques_overlap'] = pct_ref_question_overlap(data_data)\n",
    "\n",
    "        # Add count statistics to a total field\n",
    "        statistics['total']['num_passages'] += \\\n",
    "            statistics[dataset]['num_passages']\n",
    "        statistics['total']['num_ques_ref_pairs'] += \\\n",
    "            statistics[dataset]['num_ques_ref_pairs']\n",
    "        statistics['total']['num_instances'] += \\\n",
    "            statistics[dataset]['num_instances']\n",
    "\n",
    "        # Compute average length statistics\n",
    "        if compute_average_lengths:\n",
    "            statistics[dataset]['avg_passage_len'] = \\\n",
    "                avg_passage_len(data_data)\n",
    "            statistics[dataset]['avg_question_len'] = \\\n",
    "                avg_question_len(data_data)\n",
    "            statistics[dataset]['avg_reference_len'] = \\\n",
    "                avg_reference_len(data_data)\n",
    "            statistics[dataset]['avg_candidate_len'] = \\\n",
    "                avg_candidate_len(data_data)\n",
    "            statistics[dataset]['avg_candidate_scores'] = \\\n",
    "                avg_candidate_score(data_data)\n",
    "            statistics[dataset]['avg_candidate_agreement'] = \\\n",
    "                avg_candidate_agreement(data_data)\n",
    "\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b18944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                        | 0/6 [00:00<?, ?it/s]/home/kat/miniconda3/envs/gqa-env/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [04:16<00:00, 42.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_passages</th>\n",
       "      <th>num_ques_ref_pairs</th>\n",
       "      <th>num_instances</th>\n",
       "      <th>avg_annots_per_ques_ref_pair</th>\n",
       "      <th>pct_ref_cont_overlap</th>\n",
       "      <th>pct_ref_ques_overlap</th>\n",
       "      <th>avg_passage_len</th>\n",
       "      <th>avg_question_len</th>\n",
       "      <th>avg_reference_len</th>\n",
       "      <th>avg_candidate_len</th>\n",
       "      <th>avg_candidate_scores</th>\n",
       "      <th>avg_candidate_agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cosmosqa</th>\n",
       "      <td>1064.0</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>5033.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop</th>\n",
       "      <td>80.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>687.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>218.9</td>\n",
       "      <td>11.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcscript</th>\n",
       "      <td>462.0</td>\n",
       "      <td>2940.0</td>\n",
       "      <td>7210.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>narrativeqa</th>\n",
       "      <td>85.0</td>\n",
       "      <td>2249.0</td>\n",
       "      <td>7471.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>333.1</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quoref</th>\n",
       "      <td>184.0</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>3259.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.2</td>\n",
       "      <td>15.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socialiqa</th>\n",
       "      <td>3075.0</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>7409.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>4950.0</td>\n",
       "      <td>11043.0</td>\n",
       "      <td>31069.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             num_passages  num_ques_ref_pairs  num_instances  \\\n",
       "cosmosqa           1064.0              1139.0         5033.0   \n",
       "drop                 80.0               542.0          687.0   \n",
       "mcscript            462.0              2940.0         7210.0   \n",
       "narrativeqa          85.0              2249.0         7471.0   \n",
       "quoref              184.0              1098.0         3259.0   \n",
       "socialiqa          3075.0              3075.0         7409.0   \n",
       "total              4950.0             11043.0        31069.0   \n",
       "\n",
       "             avg_annots_per_ques_ref_pair  pct_ref_cont_overlap  \\\n",
       "cosmosqa                              4.4                   0.0   \n",
       "drop                                  1.3                   0.6   \n",
       "mcscript                              2.5                   0.1   \n",
       "narrativeqa                           3.3                   0.2   \n",
       "quoref                                3.0                   0.9   \n",
       "socialiqa                             2.4                   0.0   \n",
       "total                                 NaN                   NaN   \n",
       "\n",
       "             pct_ref_ques_overlap  avg_passage_len  avg_question_len  \\\n",
       "cosmosqa                      0.0             72.8              10.8   \n",
       "drop                          0.2            218.9              11.6   \n",
       "mcscript                      0.0            197.1               7.8   \n",
       "narrativeqa                   0.0            333.1               9.6   \n",
       "quoref                        0.0            324.2              15.8   \n",
       "socialiqa                     0.0             15.7               7.2   \n",
       "total                         NaN              NaN               NaN   \n",
       "\n",
       "             avg_reference_len  avg_candidate_len  avg_candidate_scores  \\\n",
       "cosmosqa                   7.5                8.8                   2.2   \n",
       "drop                       3.9                5.2                   2.2   \n",
       "mcscript                   4.3                4.1                   2.6   \n",
       "narrativeqa                5.8                5.9                   2.7   \n",
       "quoref                     2.3                8.2                   1.9   \n",
       "socialiqa                  3.9                3.9                   2.4   \n",
       "total                      NaN                NaN                   NaN   \n",
       "\n",
       "             avg_candidate_agreement  \n",
       "cosmosqa                         2.2  \n",
       "drop                             2.2  \n",
       "mcscript                         2.6  \n",
       "narrativeqa                      2.7  \n",
       "quoref                           1.9  \n",
       "socialiqa                        2.4  \n",
       "total                            NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_train = pd.DataFrame(get_statistics_for_split(f'{MOCHA_DIR_PATH}/train.json', compute_average_lengths=True)).T\n",
    "df_train.sort_index().to_clipboard()\n",
    "df_train.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a0e36bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                        | 0/6 [00:00<?, ?it/s]/home/kat/miniconda3/envs/gqa-env/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:31<00:00,  5.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_passages</th>\n",
       "      <th>num_ques_ref_pairs</th>\n",
       "      <th>num_instances</th>\n",
       "      <th>avg_annots_per_ques_ref_pair</th>\n",
       "      <th>pct_ref_cont_overlap</th>\n",
       "      <th>pct_ref_ques_overlap</th>\n",
       "      <th>avg_passage_len</th>\n",
       "      <th>avg_question_len</th>\n",
       "      <th>avg_reference_len</th>\n",
       "      <th>avg_candidate_len</th>\n",
       "      <th>avg_candidate_scores</th>\n",
       "      <th>avg_candidate_agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cosmosqa</th>\n",
       "      <td>142.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.7</td>\n",
       "      <td>10.8</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop</th>\n",
       "      <td>10.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>197.7</td>\n",
       "      <td>12.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcscript</th>\n",
       "      <td>61.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.6</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>narrativeqa</th>\n",
       "      <td>11.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>348.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quoref</th>\n",
       "      <td>24.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>336.2</td>\n",
       "      <td>14.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socialiqa</th>\n",
       "      <td>414.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>662.0</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>4009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             num_passages  num_ques_ref_pairs  num_instances  \\\n",
       "cosmosqa            142.0               156.0          683.0   \n",
       "drop                 10.0                76.0           97.0   \n",
       "mcscript             61.0               390.0          978.0   \n",
       "narrativeqa          11.0               277.0          890.0   \n",
       "quoref               24.0               123.0          344.0   \n",
       "socialiqa           414.0               414.0         1017.0   \n",
       "total               662.0              1436.0         4009.0   \n",
       "\n",
       "             avg_annots_per_ques_ref_pair  pct_ref_cont_overlap  \\\n",
       "cosmosqa                              4.4                   0.0   \n",
       "drop                                  1.3                   0.7   \n",
       "mcscript                              2.5                   0.0   \n",
       "narrativeqa                           3.2                   0.2   \n",
       "quoref                                2.8                   0.9   \n",
       "socialiqa                             2.5                   0.0   \n",
       "total                                 NaN                   NaN   \n",
       "\n",
       "             pct_ref_ques_overlap  avg_passage_len  avg_question_len  \\\n",
       "cosmosqa                      0.0             77.7              10.8   \n",
       "drop                          0.3            197.7              12.1   \n",
       "mcscript                      0.0            197.6               8.1   \n",
       "narrativeqa                   0.0            348.5               9.5   \n",
       "quoref                        0.0            336.2              14.4   \n",
       "socialiqa                     0.0             15.5               7.2   \n",
       "total                         NaN              NaN               NaN   \n",
       "\n",
       "             avg_reference_len  avg_candidate_len  avg_candidate_scores  \\\n",
       "cosmosqa                   7.3                8.7                   2.2   \n",
       "drop                       3.6                6.7                   2.0   \n",
       "mcscript                   4.1                4.0                   2.4   \n",
       "narrativeqa                4.9                5.7                   2.6   \n",
       "quoref                     2.3                8.0                   1.9   \n",
       "socialiqa                  3.9                3.9                   2.4   \n",
       "total                      NaN                NaN                   NaN   \n",
       "\n",
       "             avg_candidate_agreement  \n",
       "cosmosqa                         2.2  \n",
       "drop                             2.0  \n",
       "mcscript                         2.4  \n",
       "narrativeqa                      2.6  \n",
       "quoref                           1.9  \n",
       "socialiqa                        2.4  \n",
       "total                            NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev = pd.DataFrame(get_statistics_for_split(f'{MOCHA_DIR_PATH}/dev.json', compute_average_lengths=True)).T\n",
    "df_dev.sort_index().to_clipboard() \n",
    "df_dev.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ed05890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 306.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_passages</th>\n",
       "      <th>num_ques_ref_pairs</th>\n",
       "      <th>num_instances</th>\n",
       "      <th>avg_annots_per_ques_ref_pair</th>\n",
       "      <th>pct_ref_cont_overlap</th>\n",
       "      <th>pct_ref_ques_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cosmosqa</th>\n",
       "      <td>212.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop</th>\n",
       "      <td>17.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcscript</th>\n",
       "      <td>93.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>narrativeqa</th>\n",
       "      <td>18.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1707.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quoref</th>\n",
       "      <td>38.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socialiqa</th>\n",
       "      <td>611.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>989.0</td>\n",
       "      <td>2217.0</td>\n",
       "      <td>6321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             num_passages  num_ques_ref_pairs  num_instances  \\\n",
       "cosmosqa            212.0               226.0         1017.0   \n",
       "drop                 17.0               117.0          152.0   \n",
       "mcscript             93.0               583.0         1409.0   \n",
       "narrativeqa          18.0               500.0         1707.0   \n",
       "quoref               38.0               180.0          509.0   \n",
       "socialiqa           611.0               611.0         1527.0   \n",
       "total               989.0              2217.0         6321.0   \n",
       "\n",
       "             avg_annots_per_ques_ref_pair  pct_ref_cont_overlap  \\\n",
       "cosmosqa                              4.5                   0.0   \n",
       "drop                                  1.3                   0.5   \n",
       "mcscript                              2.4                   0.1   \n",
       "narrativeqa                           3.4                   0.2   \n",
       "quoref                                2.8                   0.8   \n",
       "socialiqa                             2.5                   0.0   \n",
       "total                                 NaN                   NaN   \n",
       "\n",
       "             pct_ref_ques_overlap  \n",
       "cosmosqa                      0.0  \n",
       "drop                          0.3  \n",
       "mcscript                      0.0  \n",
       "narrativeqa                   0.0  \n",
       "quoref                        0.0  \n",
       "socialiqa                     0.0  \n",
       "total                         NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(get_statistics_for_split(f'{MOCHA_DIR_PATH}/test_no_labels.json')).T\n",
    "df_test.sort_index().to_clipboard()\n",
    "df_test.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8626f6a8",
   "metadata": {},
   "source": [
    "## Analysis `score>=3`\n",
    "\n",
    "An agreement score above 3, implies the answers is either equivalent or more correct than the reference. Let us get a perspective of how the stats change with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7db3278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [01:48<00:00, 18.10s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_passages</th>\n",
       "      <th>num_ques_ref_pairs</th>\n",
       "      <th>num_instances</th>\n",
       "      <th>avg_annots_per_ques_ref_pair</th>\n",
       "      <th>pct_ref_cont_overlap</th>\n",
       "      <th>pct_ref_ques_overlap</th>\n",
       "      <th>avg_passage_len</th>\n",
       "      <th>avg_question_len</th>\n",
       "      <th>avg_reference_len</th>\n",
       "      <th>avg_candidate_len</th>\n",
       "      <th>avg_candidate_scores</th>\n",
       "      <th>avg_candidate_agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cosmosqa</th>\n",
       "      <td>917.0</td>\n",
       "      <td>966.0</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.1</td>\n",
       "      <td>10.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop</th>\n",
       "      <td>76.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcscript</th>\n",
       "      <td>455.0</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>3340.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>narrativeqa</th>\n",
       "      <td>85.0</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>3759.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>333.4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quoref</th>\n",
       "      <td>172.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329.1</td>\n",
       "      <td>16.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socialiqa</th>\n",
       "      <td>2306.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>4011.0</td>\n",
       "      <td>8005.0</td>\n",
       "      <td>13195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             num_passages  num_ques_ref_pairs  num_instances  \\\n",
       "cosmosqa            917.0               966.0         1752.0   \n",
       "drop                 76.0               231.0          271.0   \n",
       "mcscript            455.0              2050.0         3340.0   \n",
       "narrativeqa          85.0              1811.0         3759.0   \n",
       "quoref              172.0               641.0         1072.0   \n",
       "socialiqa          2306.0              2306.0         3001.0   \n",
       "total              4011.0              8005.0        13195.0   \n",
       "\n",
       "             avg_annots_per_ques_ref_pair  pct_ref_cont_overlap  \\\n",
       "cosmosqa                              1.8                   0.0   \n",
       "drop                                  1.2                   0.5   \n",
       "mcscript                              1.6                   0.1   \n",
       "narrativeqa                           2.1                   0.2   \n",
       "quoref                                1.7                   0.8   \n",
       "socialiqa                             1.3                   0.0   \n",
       "total                                 NaN                   NaN   \n",
       "\n",
       "             pct_ref_ques_overlap  avg_passage_len  avg_question_len  \\\n",
       "cosmosqa                      0.0             73.1              10.8   \n",
       "drop                          0.1            222.0              11.4   \n",
       "mcscript                      0.0            197.6               7.6   \n",
       "narrativeqa                   0.0            333.4               9.6   \n",
       "quoref                        0.0            329.1              16.4   \n",
       "socialiqa                     0.0             15.6               7.1   \n",
       "total                         NaN              NaN               NaN   \n",
       "\n",
       "             avg_reference_len  avg_candidate_len  avg_candidate_scores  \\\n",
       "cosmosqa                   7.4                7.5                   4.3   \n",
       "drop                       3.8                3.3                   3.8   \n",
       "mcscript                   4.1                3.8                   4.2   \n",
       "narrativeqa                5.6                5.9                   4.3   \n",
       "quoref                     2.5                5.6                   3.5   \n",
       "socialiqa                  3.8                3.7                   4.2   \n",
       "total                      NaN                NaN                   NaN   \n",
       "\n",
       "             avg_candidate_agreement  \n",
       "cosmosqa                         4.3  \n",
       "drop                             3.8  \n",
       "mcscript                         4.2  \n",
       "narrativeqa                      4.3  \n",
       "quoref                           3.5  \n",
       "socialiqa                        4.2  \n",
       "total                            NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_train = pd.DataFrame(get_statistics_for_split(f'{MOCHA_DIR_PATH}/train.json', \n",
    "                                                 compute_average_lengths=True, \n",
    "                                                 agreement_score=3)).T\n",
    "df_train.sort_index().to_clipboard()\n",
    "df_train.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4159f6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                        | 0/6 [00:00<?, ?it/s]/home/kat/miniconda3/envs/gqa-env/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:11<00:00,  1.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_passages</th>\n",
       "      <th>num_ques_ref_pairs</th>\n",
       "      <th>num_instances</th>\n",
       "      <th>avg_annots_per_ques_ref_pair</th>\n",
       "      <th>pct_ref_cont_overlap</th>\n",
       "      <th>pct_ref_ques_overlap</th>\n",
       "      <th>avg_passage_len</th>\n",
       "      <th>avg_question_len</th>\n",
       "      <th>avg_reference_len</th>\n",
       "      <th>avg_candidate_len</th>\n",
       "      <th>avg_candidate_scores</th>\n",
       "      <th>avg_candidate_agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cosmosqa</th>\n",
       "      <td>115.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.5</td>\n",
       "      <td>10.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop</th>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>210.7</td>\n",
       "      <td>12.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcscript</th>\n",
       "      <td>60.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>narrativeqa</th>\n",
       "      <td>11.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>351.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quoref</th>\n",
       "      <td>21.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>341.7</td>\n",
       "      <td>14.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socialiqa</th>\n",
       "      <td>303.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>520.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>1438.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             num_passages  num_ques_ref_pairs  num_instances  \\\n",
       "cosmosqa            115.0               121.0          214.0   \n",
       "drop                 10.0                24.0           26.0   \n",
       "mcscript             60.0               239.0          363.0   \n",
       "narrativeqa          11.0               205.0          379.0   \n",
       "quoref               21.0                56.0           93.0   \n",
       "socialiqa           303.0               303.0          363.0   \n",
       "total               520.0               948.0         1438.0   \n",
       "\n",
       "             avg_annots_per_ques_ref_pair  pct_ref_cont_overlap  \\\n",
       "cosmosqa                              1.8                   0.0   \n",
       "drop                                  1.1                   0.6   \n",
       "mcscript                              1.5                   0.0   \n",
       "narrativeqa                           1.8                   0.2   \n",
       "quoref                                1.7                   0.8   \n",
       "socialiqa                             1.2                   0.0   \n",
       "total                                 NaN                   NaN   \n",
       "\n",
       "             pct_ref_ques_overlap  avg_passage_len  avg_question_len  \\\n",
       "cosmosqa                      0.0             79.5              10.7   \n",
       "drop                          0.4            210.7              12.8   \n",
       "mcscript                      0.0            197.3               7.8   \n",
       "narrativeqa                   0.0            351.6               9.5   \n",
       "quoref                        0.0            341.7              14.8   \n",
       "socialiqa                     0.0             15.7               7.1   \n",
       "total                         NaN              NaN               NaN   \n",
       "\n",
       "             avg_reference_len  avg_candidate_len  avg_candidate_scores  \\\n",
       "cosmosqa                   7.5                7.2                   4.4   \n",
       "drop                       3.1                4.0                   4.3   \n",
       "mcscript                   3.7                3.5                   4.3   \n",
       "narrativeqa                4.7                5.3                   4.2   \n",
       "quoref                     2.6                4.6                   3.5   \n",
       "socialiqa                  3.8                3.7                   4.2   \n",
       "total                      NaN                NaN                   NaN   \n",
       "\n",
       "             avg_candidate_agreement  \n",
       "cosmosqa                         4.4  \n",
       "drop                             4.3  \n",
       "mcscript                         4.3  \n",
       "narrativeqa                      4.2  \n",
       "quoref                           3.5  \n",
       "socialiqa                        4.2  \n",
       "total                            NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev = pd.DataFrame(get_statistics_for_split(f'{MOCHA_DIR_PATH}/dev.json', compute_average_lengths=True, agreement_score=3)).T\n",
    "df_dev.sort_index().to_clipboard()\n",
    "df_dev.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22201221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
